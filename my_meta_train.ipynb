{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import cv2\n",
    "from skimage import io\n",
    "import albumentations as A\n",
    "import torch\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.nn import functional as F\n",
    "from glob import glob\n",
    "import sklearn\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from torch import nn\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "SEED = 42\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')\n",
    "torch.manual_seed(47)\n",
    "np.random.seed(47)\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "device_ids=range(torch.cuda.device_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = '/home/xhzhu/data/my_siim'\n",
    "df_folds = pd.read_csv(f'{DATA_PATH}/folds_13062020.csv', index_col='image_id')\n",
    "set(df_folds[df_folds['fold'] == 0]['patient_id'].values).intersection(df_folds[df_folds['fold'] == 1]['patient_id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>target</th>\n",
       "      <th>source</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "      <th>stratify_group</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ISIC_2637011</th>\n",
       "      <td>IP_7279968</td>\n",
       "      <td>0</td>\n",
       "      <td>ISIC20</td>\n",
       "      <td>male</td>\n",
       "      <td>45.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0015719</th>\n",
       "      <td>IP_3075186</td>\n",
       "      <td>0</td>\n",
       "      <td>ISIC20</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0052212</th>\n",
       "      <td>IP_2842074</td>\n",
       "      <td>0</td>\n",
       "      <td>ISIC20</td>\n",
       "      <td>female</td>\n",
       "      <td>50.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0068279</th>\n",
       "      <td>IP_6890425</td>\n",
       "      <td>0</td>\n",
       "      <td>ISIC20</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0074268</th>\n",
       "      <td>IP_8723313</td>\n",
       "      <td>0</td>\n",
       "      <td>ISIC20</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0071181</th>\n",
       "      <td>BCN_0002740</td>\n",
       "      <td>0</td>\n",
       "      <td>ISIC19</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0071317</th>\n",
       "      <td>BCN_0003003</td>\n",
       "      <td>0</td>\n",
       "      <td>ISIC19</td>\n",
       "      <td>male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0071505</th>\n",
       "      <td>BCN_0005307</td>\n",
       "      <td>0</td>\n",
       "      <td>ISIC19</td>\n",
       "      <td>female</td>\n",
       "      <td>40.0</td>\n",
       "      <td>torso</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0071594</th>\n",
       "      <td>BCN_0004562</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC19</td>\n",
       "      <td>female</td>\n",
       "      <td>50.0</td>\n",
       "      <td>torso</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0072850</th>\n",
       "      <td>BCN_0001347</td>\n",
       "      <td>0</td>\n",
       "      <td>ISIC19</td>\n",
       "      <td>female</td>\n",
       "      <td>50.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57224 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               patient_id  target  source     sex  age_approx  \\\n",
       "image_id                                                        \n",
       "ISIC_2637011   IP_7279968       0  ISIC20    male        45.0   \n",
       "ISIC_0015719   IP_3075186       0  ISIC20  female        45.0   \n",
       "ISIC_0052212   IP_2842074       0  ISIC20  female        50.0   \n",
       "ISIC_0068279   IP_6890425       0  ISIC20  female        45.0   \n",
       "ISIC_0074268   IP_8723313       0  ISIC20  female        55.0   \n",
       "...                   ...     ...     ...     ...         ...   \n",
       "ISIC_0071181  BCN_0002740       0  ISIC19  female        30.0   \n",
       "ISIC_0071317  BCN_0003003       0  ISIC19    male        80.0   \n",
       "ISIC_0071505  BCN_0005307       0  ISIC19  female        40.0   \n",
       "ISIC_0071594  BCN_0004562       1  ISIC19  female        50.0   \n",
       "ISIC_0072850  BCN_0001347       0  ISIC19  female        50.0   \n",
       "\n",
       "             anatom_site_general_challenge  stratify_group  fold  \n",
       "image_id                                                          \n",
       "ISIC_2637011                     head/neck              31     0  \n",
       "ISIC_0015719               upper extremity               7     2  \n",
       "ISIC_0052212               lower extremity               5     4  \n",
       "ISIC_0068279                     head/neck               7     0  \n",
       "ISIC_0074268               upper extremity               6     4  \n",
       "...                                    ...             ...   ...  \n",
       "ISIC_0071181               lower extremity               0     1  \n",
       "ISIC_0071317               lower extremity              19     4  \n",
       "ISIC_0071505                         torso               0     0  \n",
       "ISIC_0071594                         torso               2     0  \n",
       "ISIC_0072850               upper extremity               0     3  \n",
       "\n",
       "[57224 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ISIC_0052060</th>\n",
       "      <td>IP_3579794</td>\n",
       "      <td>male</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0052349</th>\n",
       "      <td>IP_7782715</td>\n",
       "      <td>male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>lower extremity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0058510</th>\n",
       "      <td>IP_7960270</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>torso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0073313</th>\n",
       "      <td>IP_6375035</td>\n",
       "      <td>female</td>\n",
       "      <td>50.0</td>\n",
       "      <td>torso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0073502</th>\n",
       "      <td>IP_0589375</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>lower extremity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_9992485</th>\n",
       "      <td>IP_4152479</td>\n",
       "      <td>male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>torso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_9996992</th>\n",
       "      <td>IP_4890115</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>torso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_9997917</th>\n",
       "      <td>IP_2852390</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>upper extremity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_9998234</th>\n",
       "      <td>IP_8861963</td>\n",
       "      <td>male</td>\n",
       "      <td>65.0</td>\n",
       "      <td>lower extremity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_9999302</th>\n",
       "      <td>IP_6214039</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>upper extremity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10982 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              patient_id     sex  age_approx anatom_site_general_challenge\n",
       "image_name                                                                \n",
       "ISIC_0052060  IP_3579794    male        70.0                           NaN\n",
       "ISIC_0052349  IP_7782715    male        40.0               lower extremity\n",
       "ISIC_0058510  IP_7960270  female        55.0                         torso\n",
       "ISIC_0073313  IP_6375035  female        50.0                         torso\n",
       "ISIC_0073502  IP_0589375  female        45.0               lower extremity\n",
       "...                  ...     ...         ...                           ...\n",
       "ISIC_9992485  IP_4152479    male        40.0                         torso\n",
       "ISIC_9996992  IP_4890115    male        35.0                         torso\n",
       "ISIC_9997917  IP_2852390    male        25.0               upper extremity\n",
       "ISIC_9998234  IP_8861963    male        65.0               lower extremity\n",
       "ISIC_9999302  IP_6214039    male        30.0               upper extremity\n",
       "\n",
       "[10982 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"/home/xhzhu/data/siim/test.csv\", index_col='image_name')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               patient_id  target  source  sex  age_approx  \\\n",
      "image_id                                                     \n",
      "ISIC_2637011   IP_7279968       0  ISIC20  1.0    0.500000   \n",
      "ISIC_0015719   IP_3075186       0  ISIC20  0.0    0.500000   \n",
      "ISIC_0052212   IP_2842074       0  ISIC20  0.0    0.555556   \n",
      "ISIC_0068279   IP_6890425       0  ISIC20  0.0    0.500000   \n",
      "ISIC_0074268   IP_8723313       0  ISIC20  0.0    0.611111   \n",
      "...                   ...     ...     ...  ...         ...   \n",
      "ISIC_0071181  BCN_0002740       0  ISIC19  0.0    0.333333   \n",
      "ISIC_0071317  BCN_0003003       0  ISIC19  1.0    0.888889   \n",
      "ISIC_0071505  BCN_0005307       0  ISIC19  0.0    0.444444   \n",
      "ISIC_0071594  BCN_0004562       1  ISIC19  0.0    0.555556   \n",
      "ISIC_0072850  BCN_0001347       0  ISIC19  0.0    0.555556   \n",
      "\n",
      "             anatom_site_general_challenge  stratify_group  fold  \\\n",
      "image_id                                                           \n",
      "ISIC_2637011                     head/neck              31     0   \n",
      "ISIC_0015719               upper extremity               7     2   \n",
      "ISIC_0052212               lower extremity               5     4   \n",
      "ISIC_0068279                     head/neck               7     0   \n",
      "ISIC_0074268               upper extremity               6     4   \n",
      "...                                    ...             ...   ...   \n",
      "ISIC_0071181               lower extremity               0     1   \n",
      "ISIC_0071317               lower extremity              19     4   \n",
      "ISIC_0071505                         torso               0     0   \n",
      "ISIC_0071594                         torso               2     0   \n",
      "ISIC_0072850               upper extremity               0     3   \n",
      "\n",
      "              site_head/neck  site_lateral torso  site_lower extremity  \\\n",
      "image_id                                                                 \n",
      "ISIC_2637011               1                   0                     0   \n",
      "ISIC_0015719               0                   0                     0   \n",
      "ISIC_0052212               0                   0                     1   \n",
      "ISIC_0068279               1                   0                     0   \n",
      "ISIC_0074268               0                   0                     0   \n",
      "...                      ...                 ...                   ...   \n",
      "ISIC_0071181               0                   0                     1   \n",
      "ISIC_0071317               0                   0                     1   \n",
      "ISIC_0071505               0                   0                     0   \n",
      "ISIC_0071594               0                   0                     0   \n",
      "ISIC_0072850               0                   0                     0   \n",
      "\n",
      "              site_oral/genital  site_palms/soles  site_torso  site_unknown  \\\n",
      "image_id                                                                      \n",
      "ISIC_2637011                  0                 0           0             0   \n",
      "ISIC_0015719                  0                 0           0             0   \n",
      "ISIC_0052212                  0                 0           0             0   \n",
      "ISIC_0068279                  0                 0           0             0   \n",
      "ISIC_0074268                  0                 0           0             0   \n",
      "...                         ...               ...         ...           ...   \n",
      "ISIC_0071181                  0                 0           0             0   \n",
      "ISIC_0071317                  0                 0           0             0   \n",
      "ISIC_0071505                  0                 0           1             0   \n",
      "ISIC_0071594                  0                 0           1             0   \n",
      "ISIC_0072850                  0                 0           0             0   \n",
      "\n",
      "              site_upper extremity  site_nan  \n",
      "image_id                                      \n",
      "ISIC_2637011                     0         0  \n",
      "ISIC_0015719                     1         0  \n",
      "ISIC_0052212                     0         0  \n",
      "ISIC_0068279                     0         0  \n",
      "ISIC_0074268                     1         0  \n",
      "...                            ...       ...  \n",
      "ISIC_0071181                     0         0  \n",
      "ISIC_0071317                     0         0  \n",
      "ISIC_0071505                     0         0  \n",
      "ISIC_0071594                     0         0  \n",
      "ISIC_0072850                     1         0  \n",
      "\n",
      "[57224 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# One-hot encoding of anatom_site_general_challenge feature\n",
    "concat = pd.concat([df_folds['anatom_site_general_challenge'], test_df['anatom_site_general_challenge']], ignore_index=False)\n",
    "dummies = pd.get_dummies(concat, dummy_na=True, dtype=np.uint8, prefix='site')\n",
    "df_folds = pd.concat([df_folds.loc[:, :], dummies.iloc[:df_folds.shape[0]]], axis=1)\n",
    "test_df = pd.concat([test_df, dummies.iloc[df_folds.shape[0]:].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Sex features\n",
    "df_folds['sex'] = df_folds['sex'].map({'male': 1, 'female': 0})\n",
    "test_df['sex'] = test_df['sex'].map({'male': 1, 'female': 0})\n",
    "df_folds['sex'] = df_folds['sex'].fillna(-1)\n",
    "test_df['sex'] = test_df['sex'].fillna(-1)\n",
    "\n",
    "# Age features\n",
    "df_folds['age_approx'] /= df_folds['age_approx'].max()\n",
    "test_df['age_approx'] /= test_df['age_approx'].max()\n",
    "#train_df['age_approx'] = train_df['age_approx'].fillna(0)\n",
    "test_df['age_approx'] = test_df['age_approx'].fillna(0)\n",
    "\n",
    "df_folds['patient_id'] = df_folds['patient_id'].fillna(0)\n",
    "print(df_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex', 'age_approx', 'site_head/neck', 'site_lateral torso', 'site_lower extremity', 'site_oral/genital', 'site_palms/soles', 'site_torso', 'site_unknown', 'site_upper extremity', 'site_nan']\n"
     ]
    }
   ],
   "source": [
    "meta_features = ['sex', 'age_approx'] + [col for col in df_folds.columns if 'site_' in col]\n",
    "meta_features.remove('anatom_site_general_challenge')\n",
    "print(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              patient_id  target  source  sex  age_approx  \\\n",
      "image_id                                                    \n",
      "ISIC_2637011  IP_7279968       0  ISIC20  1.0    0.500000   \n",
      "ISIC_0015719  IP_3075186       0  ISIC20  0.0    0.500000   \n",
      "ISIC_0052212  IP_2842074       0  ISIC20  0.0    0.555556   \n",
      "ISIC_0068279  IP_6890425       0  ISIC20  0.0    0.500000   \n",
      "ISIC_0074268  IP_8723313       0  ISIC20  0.0    0.611111   \n",
      "ISIC_0074311  IP_2950485       0  ISIC20  0.0    0.444444   \n",
      "ISIC_0074542  IP_4698288       0  ISIC20  1.0    0.277778   \n",
      "ISIC_0075663  IP_6017204       0  ISIC20  0.0    0.388889   \n",
      "ISIC_0075914  IP_7622888       0  ISIC20  1.0    0.333333   \n",
      "ISIC_0076262  IP_5075533       0  ISIC20  0.0    0.555556   \n",
      "\n",
      "             anatom_site_general_challenge  stratify_group  fold  \\\n",
      "image_id                                                           \n",
      "ISIC_2637011                     head/neck              31     0   \n",
      "ISIC_0015719               upper extremity               7     2   \n",
      "ISIC_0052212               lower extremity               5     4   \n",
      "ISIC_0068279                     head/neck               7     0   \n",
      "ISIC_0074268               upper extremity               6     4   \n",
      "ISIC_0074311               lower extremity               9     2   \n",
      "ISIC_0074542               lower extremity              27     0   \n",
      "ISIC_0075663                         torso               7     1   \n",
      "ISIC_0075914                         torso              28     3   \n",
      "ISIC_0076262               lower extremity               7     0   \n",
      "\n",
      "              site_head/neck  site_lateral torso  site_lower extremity  \\\n",
      "image_id                                                                 \n",
      "ISIC_2637011               1                   0                     0   \n",
      "ISIC_0015719               0                   0                     0   \n",
      "ISIC_0052212               0                   0                     1   \n",
      "ISIC_0068279               1                   0                     0   \n",
      "ISIC_0074268               0                   0                     0   \n",
      "ISIC_0074311               0                   0                     1   \n",
      "ISIC_0074542               0                   0                     1   \n",
      "ISIC_0075663               0                   0                     0   \n",
      "ISIC_0075914               0                   0                     0   \n",
      "ISIC_0076262               0                   0                     1   \n",
      "\n",
      "              site_oral/genital  site_palms/soles  site_torso  site_unknown  \\\n",
      "image_id                                                                      \n",
      "ISIC_2637011                  0                 0           0             0   \n",
      "ISIC_0015719                  0                 0           0             0   \n",
      "ISIC_0052212                  0                 0           0             0   \n",
      "ISIC_0068279                  0                 0           0             0   \n",
      "ISIC_0074268                  0                 0           0             0   \n",
      "ISIC_0074311                  0                 0           0             0   \n",
      "ISIC_0074542                  0                 0           0             0   \n",
      "ISIC_0075663                  0                 0           1             0   \n",
      "ISIC_0075914                  0                 0           1             0   \n",
      "ISIC_0076262                  0                 0           0             0   \n",
      "\n",
      "              site_upper extremity  site_nan  \n",
      "image_id                                      \n",
      "ISIC_2637011                     0         0  \n",
      "ISIC_0015719                     1         0  \n",
      "ISIC_0052212                     0         0  \n",
      "ISIC_0068279                     0         0  \n",
      "ISIC_0074268                     1         0  \n",
      "ISIC_0074311                     0         0  \n",
      "ISIC_0074542                     0         0  \n",
      "ISIC_0075663                     0         0  \n",
      "ISIC_0075914                     0         0  \n",
      "ISIC_0076262                     0         0  \n"
     ]
    }
   ],
   "source": [
    "print(df_folds.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>target</th>\n",
       "      <th>source</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "      <th>stratify_group</th>\n",
       "      <th>fold</th>\n",
       "      <th>site_head/neck</th>\n",
       "      <th>site_lateral torso</th>\n",
       "      <th>site_lower extremity</th>\n",
       "      <th>site_oral/genital</th>\n",
       "      <th>site_palms/soles</th>\n",
       "      <th>site_torso</th>\n",
       "      <th>site_unknown</th>\n",
       "      <th>site_upper extremity</th>\n",
       "      <th>site_nan</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ISIC_2637011</th>\n",
       "      <td>IP_7279968</td>\n",
       "      <td>0</td>\n",
       "      <td>ISIC20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0068279</th>\n",
       "      <td>IP_6890425</td>\n",
       "      <td>0</td>\n",
       "      <td>ISIC20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0074542</th>\n",
       "      <td>IP_4698288</td>\n",
       "      <td>0</td>\n",
       "      <td>ISIC20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0076262</th>\n",
       "      <td>IP_5075533</td>\n",
       "      <td>0</td>\n",
       "      <td>ISIC20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0076995</th>\n",
       "      <td>IP_2235340</td>\n",
       "      <td>0</td>\n",
       "      <td>ISIC20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>torso</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0069229</th>\n",
       "      <td>BCN_0000402</td>\n",
       "      <td>0</td>\n",
       "      <td>ISIC19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>torso</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0069769</th>\n",
       "      <td>BCN_0001158</td>\n",
       "      <td>0</td>\n",
       "      <td>ISIC19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0070306</th>\n",
       "      <td>BCN_0002580</td>\n",
       "      <td>0</td>\n",
       "      <td>ISIC19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>palms/soles</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0071505</th>\n",
       "      <td>BCN_0005307</td>\n",
       "      <td>0</td>\n",
       "      <td>ISIC19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>torso</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0071594</th>\n",
       "      <td>BCN_0004562</td>\n",
       "      <td>1</td>\n",
       "      <td>ISIC19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>torso</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11444 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               patient_id  target  source  sex  age_approx  \\\n",
       "image_id                                                     \n",
       "ISIC_2637011   IP_7279968       0  ISIC20  1.0    0.500000   \n",
       "ISIC_0068279   IP_6890425       0  ISIC20  0.0    0.500000   \n",
       "ISIC_0074542   IP_4698288       0  ISIC20  1.0    0.277778   \n",
       "ISIC_0076262   IP_5075533       0  ISIC20  0.0    0.555556   \n",
       "ISIC_0076995   IP_2235340       0  ISIC20  0.0    0.611111   \n",
       "...                   ...     ...     ...  ...         ...   \n",
       "ISIC_0069229  BCN_0000402       0  ISIC19  1.0    0.722222   \n",
       "ISIC_0069769  BCN_0001158       0  ISIC19  0.0    0.944444   \n",
       "ISIC_0070306  BCN_0002580       0  ISIC19  0.0    0.333333   \n",
       "ISIC_0071505  BCN_0005307       0  ISIC19  0.0    0.444444   \n",
       "ISIC_0071594  BCN_0004562       1  ISIC19  0.0    0.555556   \n",
       "\n",
       "             anatom_site_general_challenge  stratify_group  fold  \\\n",
       "image_id                                                           \n",
       "ISIC_2637011                     head/neck              31     0   \n",
       "ISIC_0068279                     head/neck               7     0   \n",
       "ISIC_0074542               lower extremity              27     0   \n",
       "ISIC_0076262               lower extremity               7     0   \n",
       "ISIC_0076995                         torso               5     0   \n",
       "...                                    ...             ...   ...   \n",
       "ISIC_0069229                         torso              19     0   \n",
       "ISIC_0069769                     head/neck               0     0   \n",
       "ISIC_0070306                   palms/soles               0     0   \n",
       "ISIC_0071505                         torso               0     0   \n",
       "ISIC_0071594                         torso               2     0   \n",
       "\n",
       "              site_head/neck  site_lateral torso  site_lower extremity  \\\n",
       "image_id                                                                 \n",
       "ISIC_2637011               1                   0                     0   \n",
       "ISIC_0068279               1                   0                     0   \n",
       "ISIC_0074542               0                   0                     1   \n",
       "ISIC_0076262               0                   0                     1   \n",
       "ISIC_0076995               0                   0                     0   \n",
       "...                      ...                 ...                   ...   \n",
       "ISIC_0069229               0                   0                     0   \n",
       "ISIC_0069769               1                   0                     0   \n",
       "ISIC_0070306               0                   0                     0   \n",
       "ISIC_0071505               0                   0                     0   \n",
       "ISIC_0071594               0                   0                     0   \n",
       "\n",
       "              site_oral/genital  site_palms/soles  site_torso  site_unknown  \\\n",
       "image_id                                                                      \n",
       "ISIC_2637011                  0                 0           0             0   \n",
       "ISIC_0068279                  0                 0           0             0   \n",
       "ISIC_0074542                  0                 0           0             0   \n",
       "ISIC_0076262                  0                 0           0             0   \n",
       "ISIC_0076995                  0                 0           1             0   \n",
       "...                         ...               ...         ...           ...   \n",
       "ISIC_0069229                  0                 0           1             0   \n",
       "ISIC_0069769                  0                 0           0             0   \n",
       "ISIC_0070306                  0                 1           0             0   \n",
       "ISIC_0071505                  0                 0           1             0   \n",
       "ISIC_0071594                  0                 0           1             0   \n",
       "\n",
       "              site_upper extremity  site_nan  \n",
       "image_id                                      \n",
       "ISIC_2637011                     0         0  \n",
       "ISIC_0068279                     0         0  \n",
       "ISIC_0074542                     0         0  \n",
       "ISIC_0076262                     0         0  \n",
       "ISIC_0076995                     0         0  \n",
       "...                            ...       ...  \n",
       "ISIC_0069229                     0         0  \n",
       "ISIC_0069769                     0         0  \n",
       "ISIC_0070306                     0         0  \n",
       "ISIC_0071505                     0         0  \n",
       "ISIC_0071594                     0         0  \n",
       "\n",
       "[11444 rows x 17 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_folds[df_folds['fold'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_train_transforms():\n",
    "    return A.Compose([\n",
    "            A.RandomSizedCrop(min_max_height=(400, 400), height=512, width=512, p=0.5),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "#             A.RandomBrightness(p=0.5),\n",
    "#             A.RandomContrast(p=0.5),\n",
    "#             A.RandomGamma(p=0.5),\n",
    "#             A.ChannelShuffle(p=0.5),\n",
    "            #A.Resize(height=512, width=512, p=1),\n",
    "            A.Cutout(num_holes=64, max_h_size=32, max_w_size=32, fill_value=0, p=0.5),\n",
    "            ToTensorV2(p=1.0),                  \n",
    "        ], p=1.0)\n",
    "\n",
    "def get_valid_transforms():\n",
    "    return A.Compose([\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "#             A.RandomBrightness(p=0.5),\n",
    "#             A.RandomContrast(p=0.5),\n",
    "#             A.RandomGamma(p=0.5),\n",
    "#             A.ChannelShuffle(p=0.5),\n",
    "            #A.Resize(height=512, width=512, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_ROOT_PATH = f'{DATA_PATH}/512x512-dataset-melanoma/512x512-dataset-melanoma/'\n",
    "\n",
    "def onehot(size, target):\n",
    "    vec = torch.zeros(size, dtype=torch.float32)\n",
    "    vec[target] = 1.\n",
    "    return vec\n",
    "\n",
    "class DatasetRetriever(Dataset):\n",
    "\n",
    "    def __init__(self, image_ids, labels, transforms=None):\n",
    "        super().__init__()\n",
    "        self.image_ids = image_ids\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        image_id = self.image_ids[idx]\n",
    "        image = cv2.imread(f'{TRAIN_ROOT_PATH}/{image_id}.jpg', cv2.IMREAD_COLOR)\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transforms:\n",
    "            sample = {'image': image}\n",
    "            sample = self.transforms(**sample)\n",
    "            image = sample['image']\n",
    "\n",
    "        target = onehot(2, label)\n",
    "        return image, target\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.image_ids.shape[0]\n",
    "\n",
    "    def get_labels(self):\n",
    "        return list(self.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelanomaDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, image_ids, labels, train: bool = True, transforms = None, meta_features = None):\n",
    "        \"\"\"\n",
    "        Class initialization\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame with data description\n",
    "            imfolder (str): folder with images\n",
    "            train (bool): flag of whether a training dataset is being initialized or testing one\n",
    "            transforms: image transformation method to be applied\n",
    "            meta_features (list): list of features with meta information, such as sex and age\n",
    "            \n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "        self.train = train\n",
    "        self.meta_features = meta_features\n",
    "        self.image_ids = image_ids\n",
    "        self.labels = labels\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image_id = self.image_ids[index]\n",
    "        im_path = f'{TRAIN_ROOT_PATH}/{image_id}.jpg'\n",
    "        x = cv2.imread(im_path, cv2.IMREAD_COLOR)\n",
    "        x = x.astype(np.float32) / 255.0\n",
    "        meta = np.array(self.df.iloc[index][self.meta_features].values, dtype=np.float32)\n",
    "        label = self.labels[index]\n",
    "\n",
    "        if self.transforms:\n",
    "            sample = {'image': x}\n",
    "            sample = self.transforms(**sample)\n",
    "            x = sample['image']\n",
    "            \n",
    "#         if self.train:\n",
    "#             y = onehot(2, label)\n",
    "#             return (x, meta), y\n",
    "#         else:\n",
    "#             return (x, meta)\n",
    "        y = onehot(2, label)\n",
    "        return (x, meta), y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return list(self.labels)\n",
    "    \n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self, arch, n_meta_features: int):\n",
    "        super(Net, self).__init__()\n",
    "        self.arch = arch\n",
    "#         if 'ResNet' in str(arch.__class__):\n",
    "#             self.arch.fc = nn.Linear(in_features=512, out_features=500, bias=True)\n",
    "#         if 'EfficientNet' in str(arch.__class__):\n",
    "        self.arch._fc = nn.Linear(in_features=1536, out_features=500, bias=True)\n",
    "        self.meta = nn.Sequential(nn.Linear(n_meta_features, 100),\n",
    "                                  nn.BatchNorm1d(100),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(p=0.2),\n",
    "                                  nn.Linear(100, 50),  # FC layer output will have 250 features\n",
    "                                  nn.BatchNorm1d(50),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(p=0.2))\n",
    "        self.ouput = nn.Linear(500 + 50, 2)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        No sigmoid in forward because we are going to use BCEWithLogitsLoss\n",
    "        Which applies sigmoid for us when calculating a loss\n",
    "        \"\"\"\n",
    "        x = inputs[0]\n",
    "        meta = inputs[1]\n",
    "#         print(x.shape, \"^^^^^^^^^^^^^\")\n",
    "#         print(meta.shape, \"###########\")\n",
    "#         f = open(\"arch.txt\", 'w')\n",
    "#         print(arch, file=f)\n",
    "#         f.close\n",
    "#         print(self.arch, \"**********\")\n",
    "#         print(x.device, \"@@@@@@@@@@@@@\")\n",
    "        cnn_features = self.arch(x)\n",
    "\n",
    "        meta_features = self.meta(meta)\n",
    "        features = torch.cat((cnn_features, meta_features), dim=1)\n",
    "        output = self.ouput(features)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "class RocAucMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.y_true = np.array([0,1])\n",
    "        self.y_pred = np.array([0.5,0.5])\n",
    "        self.score = 0\n",
    "\n",
    "    def update(self, y_true, y_pred):\n",
    "        y_true = y_true.cpu().numpy().argmax(axis=1).clip(min=0, max=1).astype(int)\n",
    "        # y_pred = 1 - nn.functional.softmax(y_pred, dim=1).data.cpu().numpy()[:,0]\n",
    "        y_pred = nn.functional.softmax(y_pred, dim=1).data.cpu().numpy()[:,1]\n",
    "        self.y_true = np.hstack((self.y_true, y_true))\n",
    "        self.y_pred = np.hstack((self.y_pred, y_pred))\n",
    "        self.score = sklearn.metrics.roc_auc_score(self.y_true, self.y_pred)\n",
    "\n",
    "    @property\n",
    "    def avg(self):\n",
    "        return self.score\n",
    "    \n",
    "    def get_true(self):\n",
    "        return self.y_true[2:]\n",
    "\n",
    "    def get_pred(self):\n",
    "        return self.y_pred[2:]\n",
    "\n",
    "\n",
    "    \n",
    "class APScoreMeter(RocAucMeter):\n",
    "    def __init__(self):\n",
    "        super(APScoreMeter, self).__init__()\n",
    "\n",
    "    def update(self, y_true, y_pred):\n",
    "        y_true = y_true.cpu().numpy().argmax(axis=1).clip(min=0, max=1).astype(int)\n",
    "        y_pred = nn.functional.softmax(y_pred, dim=1).data.cpu().numpy()[:,1]\n",
    "        self.y_true = np.hstack((self.y_true, y_true))\n",
    "        self.y_pred = np.hstack((self.y_pred, y_pred))\n",
    "        self.score = sklearn.metrics.average_precision_score(self.y_true, self.y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, logits=False, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.logits = logits\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        if self.logits:\n",
    "            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets)\n",
    "        else:\n",
    "            BCE_loss = F.binary_cross_entropy(inputs, targets)\n",
    "\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss\n",
    "        \n",
    "class LabelSmoothing(nn.Module):\n",
    "    def __init__(self, smoothing = 0.1):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        if self.training:\n",
    "            x = x.float()\n",
    "            target = target.float()\n",
    "            logprobs = torch.nn.functional.log_softmax(x, dim = -1)\n",
    "\n",
    "            nll_loss = -logprobs * target\n",
    "            nll_loss = nll_loss.sum(-1)\n",
    "    \n",
    "            smooth_loss = -logprobs.mean(dim=-1)\n",
    "\n",
    "            loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n",
    "\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return torch.nn.functional.cross_entropy(x, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Net(\n",
       "    (arch): EfficientNet(\n",
       "      (_conv_stem): Conv2dStaticSamePadding(\n",
       "        3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_blocks): ModuleList(\n",
       "        (0): MBConvBlock(\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False\n",
       "            (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            40, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            10, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (1): MBConvBlock(\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
       "            (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (2): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
       "            (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (3): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "            (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (4): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "            (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (5): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n",
       "            (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (6): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
       "            (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (7): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
       "            (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (8): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False\n",
       "            (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (9): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "            (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (10): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "            (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (11): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "            (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (12): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
       "            (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (13): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False\n",
       "            (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (14): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "            (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (15): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "            (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (16): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "            (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (17): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
       "            (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (18): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False\n",
       "            (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (19): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "            (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (20): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "            (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (21): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "            (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (22): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "            (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (23): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
       "            (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (24): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False\n",
       "            (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "        (25): MBConvBlock(\n",
       "          (_expand_conv): Conv2dStaticSamePadding(\n",
       "            384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "            2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False\n",
       "            (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "          )\n",
       "          (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_se_reduce): Conv2dStaticSamePadding(\n",
       "            2304, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_se_expand): Conv2dStaticSamePadding(\n",
       "            96, 2304, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_project_conv): Conv2dStaticSamePadding(\n",
       "            2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "            (static_padding): Identity()\n",
       "          )\n",
       "          (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (_swish): MemoryEfficientSwish()\n",
       "        )\n",
       "      )\n",
       "      (_conv_head): Conv2dStaticSamePadding(\n",
       "        384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "      (_dropout): Dropout(p=0.3, inplace=False)\n",
       "      (_fc): Linear(in_features=1536, out_features=500, bias=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (meta): Sequential(\n",
       "      (0): Linear(in_features=11, out_features=100, bias=True)\n",
       "      (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "      (4): Linear(in_features=100, out_features=50, bias=True)\n",
       "      (5): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "      (7): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (ouput): Linear(in_features=550, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "def get_net():\n",
    "    net = EfficientNet.from_pretrained('efficientnet-b3')\n",
    "    #net._fc = nn.Linear(in_features=1536, out_features=2, bias=True)\n",
    "    #._fc = nn.Linear(in_features=2304, out_features=2, bias=True)\n",
    "    return net\n",
    "\n",
    "arch = get_net()\n",
    "net = Net(arch=arch, n_meta_features=len(meta_features))\n",
    "net = nn.DataParallel(net, device_ids=device_ids)\n",
    "net.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Fitter:\n",
    "    \n",
    "    def __init__(self, model, device, config, folder):\n",
    "        self.config = config\n",
    "        self.epoch = 0\n",
    "\n",
    "        self.base_dir = f'model/meta_b3_new/512_16/{folder}'\n",
    "        if not os.path.exists(self.base_dir):\n",
    "            os.makedirs(self.base_dir)\n",
    "\n",
    "        self.log_path = f'{self.base_dir}/log.txt'\n",
    "        self.best_score = 0\n",
    "        self.best_loss = 10**5\n",
    "        self.best_ap = 0\n",
    "        \n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.best_true = np.array([])\n",
    "        self.best_pred = np.array([])\n",
    "\n",
    "        param_optimizer = list(self.model.named_parameters())\n",
    "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ] \n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=config.lr)\n",
    "        self.scheduler = config.SchedulerClass(self.optimizer, **config.scheduler_params)\n",
    "        self.scheduler_warmup = GradualWarmupScheduler(self.optimizer, multiplier=1, total_epoch=6)\n",
    "\n",
    "#         self.criterion = FocalLoss(logits=True).to(self.device)\n",
    "        self.criterion = LabelSmoothing().to(self.device)\n",
    "        self.log(f'Fitter prepared. Device is {self.device}')\n",
    "\n",
    "    def fit(self, train_loader, validation_loader):\n",
    "        for e in range(self.config.n_epochs):\n",
    "            if self.config.verbose:\n",
    "                lr = self.optimizer.param_groups[0]['lr']\n",
    "                timestamp = datetime.utcnow().isoformat()\n",
    "                self.log(f'\\n{timestamp}\\nLR: {lr}')\n",
    "                \n",
    "            if self.epoch <= 6:\n",
    "                self.scheduler_warmup.step(self.epoch)\n",
    "                print(self.epoch, self.optimizer.param_groups[0]['lr'])\n",
    "                \n",
    "            t = time.time()\n",
    "            summary_loss, roc_auc_scores, ap_scores = self.train_one_epoch(train_loader)\n",
    "            self.log(f'[RESULT]: Train. Epoch: {self.epoch}, summary_loss: {summary_loss.avg:.5f}, roc_auc: {roc_auc_scores.avg:.5f}, ap: {ap_scores.avg:.5f}, time: {(time.time() - t):.5f}')\n",
    "\n",
    "            t = time.time()\n",
    "            f_true, f_pred, summary_loss, roc_auc_scores, ap_scores = self.validation(validation_loader)\n",
    "\n",
    "            self.log(f'[RESULT]: Val. Epoch: {self.epoch}, summary_loss: {summary_loss.avg:.5f}, roc_auc: {roc_auc_scores.avg:.5f}, ap: {ap_scores.avg:.5f}, time: {(time.time() - t):.5f}')\n",
    "            if summary_loss.avg < self.best_loss:\n",
    "                self.best_loss = summary_loss.avg\n",
    "                self.save_model(f'{self.base_dir}/best-loss-checkpoint-{str(self.epoch).zfill(3)}epoch.bin')\n",
    "                for path in sorted(glob(f'{self.base_dir}/best-loss-checkpoint-*epoch.bin'))[:-2]:\n",
    "                    os.remove(path)\n",
    "                    \n",
    "            if roc_auc_scores.avg > self.best_score:\n",
    "                self.best_score = roc_auc_scores.avg\n",
    "                self.save_model(f'{self.base_dir}/best-score-checkpoint-{str(self.epoch).zfill(3)}epoch.bin')\n",
    "                for path in sorted(glob(f'{self.base_dir}/best-score-checkpoint-*epoch.bin'))[:-2]:\n",
    "                    os.remove(path)\n",
    "                self.best_true = f_true\n",
    "                self.best_pred = f_pred\n",
    "                    \n",
    "            if ap_scores.avg > self.best_ap:\n",
    "                self.best_ap = ap_scores.avg\n",
    "                self.save_model(f'{self.base_dir}/best-ap-checkpoint-{str(self.epoch).zfill(3)}epoch.bin')\n",
    "                for path in sorted(glob(f'{self.base_dir}/best-ap-checkpoint-*epoch.bin'))[:-2]:\n",
    "                    os.remove(path)\n",
    "\n",
    "            if self.config.validation_scheduler:\n",
    "                if self.epoch > 6:\n",
    "                    self.scheduler.step(metrics=summary_loss.avg)\n",
    "\n",
    "            self.epoch += 1\n",
    "        return self.best_true , self.best_pred\n",
    "\n",
    "    def validation(self, val_loader):\n",
    "        self.model.eval()\n",
    "        summary_loss = AverageMeter()\n",
    "        roc_auc_scores = RocAucMeter()\n",
    "        ap_scores = APScoreMeter()\n",
    "        t = time.time()\n",
    "        for step, (images, targets) in enumerate(val_loader):\n",
    "            if self.config.verbose:\n",
    "                if step % self.config.verbose_step == 0:\n",
    "                    print(\n",
    "                        f'Val Step {step}/{len(val_loader)}, ' + \\\n",
    "                        f'summary_loss: {summary_loss.avg:.5f}, roc_auc: {roc_auc_scores.avg:.5f}, ap: {ap_scores.avg:.5f} ' + \\\n",
    "                        f'time: {(time.time() - t):.5f}', end='\\r'\n",
    "                    )\n",
    "            with torch.no_grad():\n",
    "                images[0] = torch.as_tensor(images[0], device=device, dtype=torch.float32)\n",
    "                images[1] = torch.as_tensor(images[1], device=device, dtype=torch.float32)\n",
    "                targets = torch.as_tensor(targets, device=device, dtype=torch.float32)\n",
    "                batch_size = images[0].shape[0]\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "                roc_auc_scores.update(targets, outputs)\n",
    "                ap_scores.update(targets, outputs)\n",
    "                summary_loss.update(loss.detach().item(), batch_size)\n",
    "        f_true = roc_auc_scores.get_true()\n",
    "        f_pred = roc_auc_scores.get_pred()\n",
    "\n",
    "        return f_true, f_pred, summary_loss, roc_auc_scores, ap_scores\n",
    "\n",
    "    def train_one_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        summary_loss = AverageMeter()\n",
    "        roc_auc_scores = RocAucMeter()\n",
    "        ap_scores = APScoreMeter()\n",
    "        t = time.time()\n",
    "        for step, (images, targets) in enumerate(train_loader):\n",
    "            if self.config.verbose:\n",
    "                if step % self.config.verbose_step == 0:\n",
    "                    print(\n",
    "                        f'Train Step {step}/{len(train_loader)}, ' + \\\n",
    "                        f'summary_loss: {summary_loss.avg:.5f}, roc_auc: {roc_auc_scores.avg:.5f}, ap: {ap_scores.avg:.5f} ' + \\\n",
    "                        f'time: {(time.time() - t):.5f}', end='\\r'\n",
    "                    )\n",
    "            images[0] = torch.as_tensor(images[0], device=device, dtype=torch.float32)\n",
    "            images[1] = torch.as_tensor(images[1], device=device, dtype=torch.float32)\n",
    "            targets = torch.as_tensor(targets, device=device, dtype=torch.float32)\n",
    "#             targets = targets.to(self.device).float()\n",
    "#             images = images.to(self.device).float()\n",
    "#             print(images[0].shape, \"&&&\")\n",
    "            batch_size = images[0].shape[0]\n",
    "#             print(batch_size, \"batch size***\")\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "#             print(np.array(images).shape, \"*****************\")\n",
    "            outputs = self.model(images)\n",
    "            loss = self.criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            \n",
    "            roc_auc_scores.update(targets, outputs)\n",
    "            ap_scores.update(targets, outputs)\n",
    "            summary_loss.update(loss.detach().item(), batch_size)\n",
    "\n",
    "            self.optimizer.step()\n",
    "\n",
    "            if self.config.step_scheduler:\n",
    "                self.scheduler.step()\n",
    "\n",
    "        return summary_loss, roc_auc_scores, ap_scores\n",
    "    \n",
    "    def save_model(self, path):\n",
    "        self.model.eval()\n",
    "        torch.save(self.model.state_dict(),path)\n",
    "\n",
    "    def save(self, path):\n",
    "        self.model.eval()\n",
    "        torch.save({\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "            'best_score': self.best_score,\n",
    "            'best_ap': self.best_ap,\n",
    "            'best_loss': self.best_loss,\n",
    "            'epoch': self.epoch,\n",
    "        }, path)\n",
    "\n",
    "    def load(self, path):\n",
    "        checkpoint = torch.load(path)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        self.best_score = checkpoint['best_score']\n",
    "        self.best_ap = checkpoint['best_ap']\n",
    "        self.best_loss = checkpoint['best_loss']\n",
    "        self.epoch = checkpoint['epoch']\n",
    "        \n",
    "    def log(self, message):\n",
    "        if self.config.verbose:\n",
    "            print(message)\n",
    "        with open(self.log_path, 'a+') as logger:\n",
    "            logger.write(f'{message}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainGlobalConfig:\n",
    "    num_workers = 2\n",
    "    batch_size = 16\n",
    "    n_epochs = 30\n",
    "    lr = 0.00003\n",
    "\n",
    "    # -------------------\n",
    "    verbose = True\n",
    "    verbose_step = 1\n",
    "    # -------------------\n",
    "\n",
    "    # --------------------\n",
    "    step_scheduler = False  # do scheduler.step after optimizer.step\n",
    "    validation_scheduler = True  # do scheduler.step after validation stage loss\n",
    "\n",
    "#     SchedulerClass = torch.optim.lr_scheduler.OneCycleLR\n",
    "#     scheduler_params = dict(\n",
    "#         max_lr=0.001,\n",
    "#         epochs=n_epochs,\n",
    "#         steps_per_epoch=int(len(train_dataset) / batch_size),\n",
    "#         pct_start=0.1,\n",
    "#         anneal_strategy='cos', \n",
    "#         final_div_factor=10**5\n",
    "#     )\n",
    "    \n",
    "    SchedulerClass = torch.optim.lr_scheduler.ReduceLROnPlateau\n",
    "    scheduler_params = dict(\n",
    "        mode='min',\n",
    "        factor=0.8,\n",
    "        patience=2,\n",
    "        verbose=False, \n",
    "        threshold=0.0001,\n",
    "        threshold_mode='abs',\n",
    "        cooldown=0, \n",
    "        min_lr=1e-8,\n",
    "        eps=1e-08\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitter prepared. Device is cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fitter = Fitter(model=net, device=torch.device('cuda:0'), config=TrainGlobalConfig, folder='base_state')\n",
    "BASE_STATE_PATH = f'{fitter.base_dir}/base_state.bin'\n",
    "fitter.save(BASE_STATE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from catalyst.data.sampler import BalanceClassSampler\n",
    "\n",
    "def train_fold(fold_number):\n",
    "    \n",
    "#     train_dataset = DatasetRetriever(\n",
    "#         image_ids=df_folds[df_folds['fold'] != fold_number].index.values,\n",
    "#         labels=df_folds[df_folds['fold'] != fold_number].target.values,\n",
    "#         transforms=get_train_transforms(),\n",
    "#     )\n",
    "    train_dataset = MelanomaDataset(df=df_folds[df_folds['fold'] != fold_number], \n",
    "                            image_ids=df_folds[df_folds['fold'] != fold_number].index.values,\n",
    "                            labels=df_folds[df_folds['fold'] != fold_number].target.values,\n",
    "                            train=True, \n",
    "                            transforms=get_train_transforms(),\n",
    "                            meta_features=meta_features)\n",
    "    df_val = df_folds[(df_folds['fold'] == fold_number) & (df_folds['source'] == 'ISIC20')]\n",
    "   \n",
    "    validation_dataset = MelanomaDataset(df=df_val, \n",
    "                            image_ids=df_val.index.values,\n",
    "                            labels=df_val.target.values,      \n",
    "                            train=False, \n",
    "                            transforms=get_valid_transforms(),\n",
    "                            meta_features=meta_features)\n",
    "#     validation_dataset = DatasetRetriever(\n",
    "#         image_ids=df_val.index.values,\n",
    "#         labels=df_val.target.values,\n",
    "#         transforms=get_valid_transforms(),\n",
    "#     )\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        sampler=BalanceClassSampler(labels=train_dataset.get_labels(), mode=\"downsampling\"),\n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        pin_memory=False,\n",
    "        drop_last=True,\n",
    "        num_workers=TrainGlobalConfig.num_workers,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        validation_dataset, \n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        num_workers=TrainGlobalConfig.num_workers,\n",
    "        shuffle=False,\n",
    "        sampler=SequentialSampler(validation_dataset),\n",
    "        pin_memory=False,\n",
    "    )\n",
    "\n",
    "    fitter = Fitter(model=net, device=torch.device('cuda:0'), config=TrainGlobalConfig, folder=f'fold{fold_number}')\n",
    "    fitter.load(BASE_STATE_PATH)\n",
    "    f_true, f_pred = fitter.fit(train_loader, val_loader)\n",
    "    return f_true, f_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitter prepared. Device is cuda:0\n",
      "\n",
      "2020-08-16T05:37:04.827392\n",
      "LR: 0.0\n",
      "0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:123: UserWarning:\n",
      "\n",
      "Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "\n",
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 0, summary_loss: 0.70475, roc_auc: 0.46863, ap: 0.48428, time: 193.61809\n",
      "[RESULT]: Val. Epoch: 0, summary_loss: 0.67340, roc_auc: 0.55244, ap: 0.02075, time: 53.94857\n",
      "\n",
      "2020-08-16T05:41:12.650671\n",
      "LR: 0.0\n",
      "1 4.9999999999999996e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 1, summary_loss: 0.62836, roc_auc: 0.74774, ap: 0.74009, time: 199.35359\n",
      "[RESULT]: Val. Epoch: 1, summary_loss: 0.44410, roc_auc: 0.81365, ap: 0.09123, time: 53.51134\n",
      "\n",
      "2020-08-16T05:45:25.748368\n",
      "LR: 4.9999999999999996e-06\n",
      "2 9.999999999999999e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 2, summary_loss: 0.52667, roc_auc: 0.85140, ap: 0.84374, time: 198.70876\n",
      "[RESULT]: Val. Epoch: 2, summary_loss: 0.32602, roc_auc: 0.86916, ap: 0.11700, time: 55.08380\n",
      "\n",
      "2020-08-16T05:49:39.806098\n",
      "LR: 9.999999999999999e-06\n",
      "3 1.5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 3, summary_loss: 0.50916, roc_auc: 0.86642, ap: 0.85699, time: 204.08876\n",
      "[RESULT]: Val. Epoch: 3, summary_loss: 0.31291, roc_auc: 0.89279, ap: 0.14237, time: 53.76667\n",
      "\n",
      "2020-08-16T05:53:57.927921\n",
      "LR: 1.5e-05\n",
      "4 1.9999999999999998e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 4, summary_loss: 0.49935, roc_auc: 0.87590, ap: 0.86505, time: 201.57491\n",
      "[RESULT]: Val. Epoch: 4, summary_loss: 0.30828, roc_auc: 0.90170, ap: 0.17210, time: 55.29819\n",
      "\n",
      "2020-08-16T05:58:15.068633\n",
      "LR: 1.9999999999999998e-05\n",
      "5 2.5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 5, summary_loss: 0.48535, roc_auc: 0.88718, ap: 0.88156, time: 204.48941\n",
      "[RESULT]: Val. Epoch: 5, summary_loss: 0.32564, roc_auc: 0.90436, ap: 0.17412, time: 53.68444\n",
      "\n",
      "2020-08-16T06:02:33.413523\n",
      "LR: 2.5e-05\n",
      "6 3e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 6, summary_loss: 0.48166, roc_auc: 0.88963, ap: 0.88082, time: 197.74240\n",
      "[RESULT]: Val. Epoch: 6, summary_loss: 0.29798, roc_auc: 0.90316, ap: 0.19268, time: 52.98506\n",
      "\n",
      "2020-08-16T06:06:44.311359\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 7, summary_loss: 0.46856, roc_auc: 0.90058, ap: 0.89419, time: 202.78458\n",
      "[RESULT]: Val. Epoch: 7, summary_loss: 0.31551, roc_auc: 0.91209, ap: 0.23469, time: 54.79924\n",
      "\n",
      "2020-08-16T06:11:02.071661\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 8, summary_loss: 0.46195, roc_auc: 0.90498, ap: 0.90178, time: 199.12930\n",
      "[RESULT]: Val. Epoch: 8, summary_loss: 0.30546, roc_auc: 0.92803, ap: 0.25863, time: 52.30236\n",
      "\n",
      "2020-08-16T06:15:13.703416\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 9, summary_loss: 0.45021, roc_auc: 0.91317, ap: 0.90731, time: 198.23582\n",
      "[RESULT]: Val. Epoch: 9, summary_loss: 0.31168, roc_auc: 0.91617, ap: 0.24409, time: 51.98848\n",
      "\n",
      "2020-08-16T06:19:23.930143\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 10, summary_loss: 0.43297, roc_auc: 0.92479, ap: 0.92323, time: 193.12269\n",
      "[RESULT]: Val. Epoch: 10, summary_loss: 0.28744, roc_auc: 0.91869, ap: 0.25412, time: 52.08606\n",
      "\n",
      "2020-08-16T06:23:29.298494\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 11, summary_loss: 0.43695, roc_auc: 0.92203, ap: 0.91720, time: 192.47523\n",
      "[RESULT]: Val. Epoch: 11, summary_loss: 0.26889, roc_auc: 0.91281, ap: 0.30068, time: 52.20660\n",
      "\n",
      "2020-08-16T06:27:34.176530\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 12, summary_loss: 0.42714, roc_auc: 0.92836, ap: 0.92365, time: 192.75904\n",
      "[RESULT]: Val. Epoch: 12, summary_loss: 0.29142, roc_auc: 0.92275, ap: 0.30030, time: 52.15154\n",
      "\n",
      "2020-08-16T06:31:39.089257\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 13, summary_loss: 0.41858, roc_auc: 0.93376, ap: 0.93153, time: 195.51462\n",
      "[RESULT]: Val. Epoch: 13, summary_loss: 0.28476, roc_auc: 0.92346, ap: 0.31138, time: 52.59599\n",
      "\n",
      "2020-08-16T06:35:47.303242\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 14, summary_loss: 0.41499, roc_auc: 0.93570, ap: 0.93207, time: 190.39683\n",
      "[RESULT]: Val. Epoch: 14, summary_loss: 0.28901, roc_auc: 0.93033, ap: 0.32426, time: 51.64150\n",
      "\n",
      "2020-08-16T06:39:49.511003\n",
      "LR: 2.4e-05\n",
      "[RESULT]: Train. Epoch: 15, summary_loss: 0.40800, roc_auc: 0.93956, ap: 0.93644, time: 189.23385\n",
      "[RESULT]: Val. Epoch: 15, summary_loss: 0.27420, roc_auc: 0.91071, ap: 0.32528, time: 51.64535\n",
      "\n",
      "2020-08-16T06:43:50.495742\n",
      "LR: 2.4e-05\n",
      "[RESULT]: Train. Epoch: 16, summary_loss: 0.40601, roc_auc: 0.94090, ap: 0.93714, time: 194.46092\n",
      "[RESULT]: Val. Epoch: 16, summary_loss: 0.27708, roc_auc: 0.92914, ap: 0.33981, time: 52.81518\n",
      "\n",
      "2020-08-16T06:47:57.865392\n",
      "LR: 2.4e-05\n",
      "[RESULT]: Train. Epoch: 17, summary_loss: 0.40085, roc_auc: 0.94376, ap: 0.94153, time: 195.67470\n",
      "[RESULT]: Val. Epoch: 17, summary_loss: 0.26818, roc_auc: 0.92769, ap: 0.30998, time: 52.61620\n",
      "\n",
      "2020-08-16T06:52:06.245905\n",
      "LR: 2.4e-05\n",
      "[RESULT]: Train. Epoch: 18, summary_loss: 0.39493, roc_auc: 0.94727, ap: 0.94288, time: 193.80265\n",
      "[RESULT]: Val. Epoch: 18, summary_loss: 0.28356, roc_auc: 0.91588, ap: 0.33185, time: 52.30396\n",
      "\n",
      "2020-08-16T06:56:12.354665\n",
      "LR: 2.4e-05\n",
      "[RESULT]: Train. Epoch: 19, summary_loss: 0.39234, roc_auc: 0.94828, ap: 0.94401, time: 195.66810\n",
      "[RESULT]: Val. Epoch: 19, summary_loss: 0.27875, roc_auc: 0.92351, ap: 0.32716, time: 55.55957\n",
      "\n",
      "2020-08-16T07:00:23.584076\n",
      "LR: 2.4e-05\n",
      "[RESULT]: Train. Epoch: 20, summary_loss: 0.38163, roc_auc: 0.95372, ap: 0.94945, time: 211.67381\n",
      "[RESULT]: Val. Epoch: 20, summary_loss: 0.28826, roc_auc: 0.92916, ap: 0.31582, time: 59.54691\n",
      "\n",
      "2020-08-16T07:04:54.806644\n",
      "LR: 1.9200000000000003e-05\n",
      "[RESULT]: Train. Epoch: 21, summary_loss: 0.38352, roc_auc: 0.95299, ap: 0.94980, time: 217.98655\n",
      "[RESULT]: Val. Epoch: 21, summary_loss: 0.28897, roc_auc: 0.92001, ap: 0.31823, time: 61.66310\n",
      "\n",
      "2020-08-16T07:09:34.458536\n",
      "LR: 1.9200000000000003e-05\n",
      "[RESULT]: Train. Epoch: 22, summary_loss: 0.37908, roc_auc: 0.95462, ap: 0.94872, time: 214.04204\n",
      "[RESULT]: Val. Epoch: 22, summary_loss: 0.29306, roc_auc: 0.92964, ap: 0.32781, time: 63.09536\n",
      "\n",
      "2020-08-16T07:14:11.597968\n",
      "LR: 1.9200000000000003e-05\n",
      "[RESULT]: Train. Epoch: 23, summary_loss: 0.37726, roc_auc: 0.95567, ap: 0.94891, time: 219.16943\n",
      "[RESULT]: Val. Epoch: 23, summary_loss: 0.27130, roc_auc: 0.91885, ap: 0.32687, time: 61.73360\n",
      "\n",
      "2020-08-16T07:18:52.502998\n",
      "LR: 1.5360000000000002e-05\n",
      "[RESULT]: Train. Epoch: 24, summary_loss: 0.37209, roc_auc: 0.95756, ap: 0.95233, time: 216.03007\n",
      "[RESULT]: Val. Epoch: 24, summary_loss: 0.27535, roc_auc: 0.92332, ap: 0.31142, time: 63.60578\n",
      "\n",
      "2020-08-16T07:23:32.141036\n",
      "LR: 1.5360000000000002e-05\n",
      "[RESULT]: Train. Epoch: 25, summary_loss: 0.37234, roc_auc: 0.95819, ap: 0.95577, time: 221.04717\n",
      "[RESULT]: Val. Epoch: 25, summary_loss: 0.28108, roc_auc: 0.93212, ap: 0.33793, time: 62.08196\n",
      "\n",
      "2020-08-16T07:28:15.425540\n",
      "LR: 1.5360000000000002e-05\n",
      "[RESULT]: Train. Epoch: 26, summary_loss: 0.36495, roc_auc: 0.96146, ap: 0.95834, time: 216.91203\n",
      "[RESULT]: Val. Epoch: 26, summary_loss: 0.27006, roc_auc: 0.93095, ap: 0.31783, time: 62.72519\n",
      "\n",
      "2020-08-16T07:32:55.065071\n",
      "LR: 1.2288000000000002e-05\n",
      "[RESULT]: Train. Epoch: 27, summary_loss: 0.36151, roc_auc: 0.96307, ap: 0.96083, time: 218.90243\n",
      "[RESULT]: Val. Epoch: 27, summary_loss: 0.27564, roc_auc: 0.92837, ap: 0.36803, time: 62.85843\n",
      "\n",
      "2020-08-16T07:37:36.959509\n",
      "LR: 1.2288000000000002e-05\n",
      "[RESULT]: Train. Epoch: 28, summary_loss: 0.36380, roc_auc: 0.96153, ap: 0.95722, time: 219.14860\n",
      "[RESULT]: Val. Epoch: 28, summary_loss: 0.27589, roc_auc: 0.93282, ap: 0.32782, time: 62.75507\n",
      "\n",
      "2020-08-16T07:42:18.993037\n",
      "LR: 1.2288000000000002e-05\n",
      "[RESULT]: Train. Epoch: 29, summary_loss: 0.35917, roc_auc: 0.96383, ap: 0.95994, time: 216.43653\n",
      "[RESULT]: Val. Epoch: 29, summary_loss: 0.28504, roc_auc: 0.92485, ap: 0.33951, time: 63.16940\n",
      "(6478,) (6478,)\n",
      "Fitter prepared. Device is cuda:0\n",
      "\n",
      "2020-08-16T07:46:58.853094\n",
      "LR: 0.0\n",
      "0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:123: UserWarning:\n",
      "\n",
      "Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "\n",
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 0, summary_loss: 0.70480, roc_auc: 0.46912, ap: 0.48179, time: 224.70544\n",
      "[RESULT]: Val. Epoch: 0, summary_loss: 0.67089, roc_auc: 0.51398, ap: 0.02182, time: 63.54739\n",
      "\n",
      "2020-08-16T07:51:47.383907\n",
      "LR: 0.0\n",
      "1 4.9999999999999996e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 1, summary_loss: 0.62333, roc_auc: 0.76137, ap: 0.74923, time: 221.32101\n",
      "[RESULT]: Val. Epoch: 1, summary_loss: 0.43602, roc_auc: 0.75629, ap: 0.07524, time: 61.82505\n",
      "\n",
      "2020-08-16T07:56:30.797501\n",
      "LR: 4.9999999999999996e-06\n",
      "2 9.999999999999999e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 2, summary_loss: 0.52878, roc_auc: 0.84908, ap: 0.83554, time: 214.39389\n",
      "[RESULT]: Val. Epoch: 2, summary_loss: 0.32544, roc_auc: 0.82331, ap: 0.10764, time: 56.85374\n",
      "\n",
      "2020-08-16T08:01:02.406388\n",
      "LR: 9.999999999999999e-06\n",
      "3 1.5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 3, summary_loss: 0.51307, roc_auc: 0.86216, ap: 0.84867, time: 208.93854\n",
      "[RESULT]: Val. Epoch: 3, summary_loss: 0.34705, roc_auc: 0.83970, ap: 0.13926, time: 56.40004\n",
      "\n",
      "2020-08-16T08:05:27.951053\n",
      "LR: 1.5e-05\n",
      "4 1.9999999999999998e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 4, summary_loss: 0.49735, roc_auc: 0.87625, ap: 0.87013, time: 205.78134\n",
      "[RESULT]: Val. Epoch: 4, summary_loss: 0.33045, roc_auc: 0.84618, ap: 0.18748, time: 55.53008\n",
      "\n",
      "2020-08-16T08:09:49.469288\n",
      "LR: 1.9999999999999998e-05\n",
      "5 2.5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 5, summary_loss: 0.48737, roc_auc: 0.88397, ap: 0.87792, time: 206.80995\n",
      "[RESULT]: Val. Epoch: 5, summary_loss: 0.32050, roc_auc: 0.85532, ap: 0.18987, time: 56.82366\n",
      "\n",
      "2020-08-16T08:14:13.406360\n",
      "LR: 2.5e-05\n",
      "6 3e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 6, summary_loss: 0.48576, roc_auc: 0.88683, ap: 0.87992, time: 209.06478\n",
      "[RESULT]: Val. Epoch: 6, summary_loss: 0.30833, roc_auc: 0.85441, ap: 0.21083, time: 56.13359\n",
      "\n",
      "2020-08-16T08:18:38.812223\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 7, summary_loss: 0.46341, roc_auc: 0.90354, ap: 0.90034, time: 204.24236\n",
      "[RESULT]: Val. Epoch: 7, summary_loss: 0.30152, roc_auc: 0.87478, ap: 0.23464, time: 54.87578\n",
      "\n",
      "2020-08-16T08:22:58.200298\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 8, summary_loss: 0.46205, roc_auc: 0.90420, ap: 0.89511, time: 202.71729\n",
      "[RESULT]: Val. Epoch: 8, summary_loss: 0.32764, roc_auc: 0.88083, ap: 0.26993, time: 52.09018\n",
      "\n",
      "2020-08-16T08:27:13.184759\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 9, summary_loss: 0.44648, roc_auc: 0.91547, ap: 0.91035, time: 196.05067\n",
      "[RESULT]: Val. Epoch: 9, summary_loss: 0.35031, roc_auc: 0.84882, ap: 0.20306, time: 51.82701\n",
      "\n",
      "2020-08-16T08:31:21.064338\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 10, summary_loss: 0.44280, roc_auc: 0.91792, ap: 0.91107, time: 197.95236\n",
      "[RESULT]: Val. Epoch: 10, summary_loss: 0.31484, roc_auc: 0.89729, ap: 0.25034, time: 53.09327\n",
      "\n",
      "2020-08-16T08:35:32.212265\n",
      "LR: 2.4e-05\n",
      "[RESULT]: Train. Epoch: 11, summary_loss: 0.42524, roc_auc: 0.92938, ap: 0.92466, time: 195.75972\n",
      "[RESULT]: Val. Epoch: 11, summary_loss: 0.29775, roc_auc: 0.89586, ap: 0.26575, time: 51.75214\n",
      "\n",
      "2020-08-16T08:39:39.828156\n",
      "LR: 2.4e-05\n",
      "[RESULT]: Train. Epoch: 12, summary_loss: 0.42668, roc_auc: 0.92834, ap: 0.92471, time: 193.60429\n",
      "[RESULT]: Val. Epoch: 12, summary_loss: 0.28580, roc_auc: 0.89122, ap: 0.25267, time: 52.16949\n",
      "\n",
      "2020-08-16T08:43:45.710194\n",
      "LR: 2.4e-05\n",
      "[RESULT]: Train. Epoch: 13, summary_loss: 0.42352, roc_auc: 0.93018, ap: 0.92485, time: 199.11126\n",
      "[RESULT]: Val. Epoch: 13, summary_loss: 0.28363, roc_auc: 0.87706, ap: 0.23389, time: 52.28995\n",
      "\n",
      "2020-08-16T08:47:57.201505\n",
      "LR: 2.4e-05\n",
      "[RESULT]: Train. Epoch: 14, summary_loss: 0.41173, roc_auc: 0.93738, ap: 0.93170, time: 196.10063\n",
      "[RESULT]: Val. Epoch: 14, summary_loss: 0.26839, roc_auc: 0.89095, ap: 0.26025, time: 52.41219\n",
      "\n",
      "2020-08-16T08:52:05.805132\n",
      "LR: 2.4e-05\n",
      "[RESULT]: Train. Epoch: 15, summary_loss: 0.41384, roc_auc: 0.93589, ap: 0.93007, time: 193.91291\n",
      "[RESULT]: Val. Epoch: 15, summary_loss: 0.28579, roc_auc: 0.88716, ap: 0.25739, time: 52.28593\n",
      "\n",
      "2020-08-16T08:56:12.005849\n",
      "LR: 2.4e-05\n",
      "[RESULT]: Train. Epoch: 16, summary_loss: 0.40167, roc_auc: 0.94298, ap: 0.93892, time: 199.87058\n",
      "[RESULT]: Val. Epoch: 16, summary_loss: 0.28701, roc_auc: 0.88986, ap: 0.27919, time: 52.28047\n",
      "\n",
      "2020-08-16T09:00:24.249249\n",
      "LR: 2.4e-05\n",
      "[RESULT]: Train. Epoch: 17, summary_loss: 0.40468, roc_auc: 0.94110, ap: 0.93566, time: 195.58232\n",
      "[RESULT]: Val. Epoch: 17, summary_loss: 0.31066, roc_auc: 0.89397, ap: 0.27104, time: 51.66567\n",
      "\n",
      "2020-08-16T09:04:31.499455\n",
      "LR: 1.9200000000000003e-05\n",
      "[RESULT]: Train. Epoch: 18, summary_loss: 0.40624, roc_auc: 0.94036, ap: 0.93424, time: 194.54653\n",
      "[RESULT]: Val. Epoch: 18, summary_loss: 0.29610, roc_auc: 0.88943, ap: 0.25021, time: 51.90565\n",
      "\n",
      "2020-08-16T09:08:37.953865\n",
      "LR: 1.9200000000000003e-05\n",
      "[RESULT]: Train. Epoch: 19, summary_loss: 0.39675, roc_auc: 0.94575, ap: 0.94135, time: 199.09427\n",
      "[RESULT]: Val. Epoch: 19, summary_loss: 0.28443, roc_auc: 0.88538, ap: 0.24987, time: 53.10296\n",
      "\n",
      "2020-08-16T09:12:50.153076\n",
      "LR: 1.9200000000000003e-05\n",
      "[RESULT]: Train. Epoch: 20, summary_loss: 0.39312, roc_auc: 0.94779, ap: 0.94431, time: 197.73576\n",
      "[RESULT]: Val. Epoch: 20, summary_loss: 0.29511, roc_auc: 0.88133, ap: 0.22821, time: 53.82778\n",
      "\n",
      "2020-08-16T09:17:01.718548\n",
      "LR: 1.5360000000000002e-05\n",
      "[RESULT]: Train. Epoch: 21, summary_loss: 0.38884, roc_auc: 0.94987, ap: 0.94560, time: 199.25580\n",
      "[RESULT]: Val. Epoch: 21, summary_loss: 0.27402, roc_auc: 0.88729, ap: 0.25072, time: 53.53019\n",
      "\n",
      "2020-08-16T09:21:14.506179\n",
      "LR: 1.5360000000000002e-05\n",
      "[RESULT]: Train. Epoch: 22, summary_loss: 0.38839, roc_auc: 0.95034, ap: 0.94696, time: 193.71973\n",
      "[RESULT]: Val. Epoch: 22, summary_loss: 0.27857, roc_auc: 0.87792, ap: 0.26094, time: 51.46876\n",
      "\n",
      "2020-08-16T09:25:19.696521\n",
      "LR: 1.5360000000000002e-05\n",
      "[RESULT]: Train. Epoch: 23, summary_loss: 0.39103, roc_auc: 0.94897, ap: 0.94492, time: 195.85330\n",
      "[RESULT]: Val. Epoch: 23, summary_loss: 0.27785, roc_auc: 0.87619, ap: 0.25690, time: 53.38940\n",
      "\n",
      "2020-08-16T09:29:28.941059\n",
      "LR: 1.2288000000000002e-05\n",
      "[RESULT]: Train. Epoch: 24, summary_loss: 0.38796, roc_auc: 0.94952, ap: 0.94196, time: 196.99951\n",
      "[RESULT]: Val. Epoch: 24, summary_loss: 0.27878, roc_auc: 0.88406, ap: 0.22789, time: 51.67549\n",
      "\n",
      "2020-08-16T09:33:37.618066\n",
      "LR: 1.2288000000000002e-05\n",
      "[RESULT]: Train. Epoch: 25, summary_loss: 0.37674, roc_auc: 0.95564, ap: 0.95065, time: 192.76358\n",
      "[RESULT]: Val. Epoch: 25, summary_loss: 0.27391, roc_auc: 0.88576, ap: 0.26022, time: 53.17951\n",
      "\n",
      "2020-08-16T09:37:43.563036\n",
      "LR: 1.2288000000000002e-05\n",
      "[RESULT]: Train. Epoch: 26, summary_loss: 0.37781, roc_auc: 0.95527, ap: 0.94994, time: 199.50042\n",
      "[RESULT]: Val. Epoch: 26, summary_loss: 0.28851, roc_auc: 0.88195, ap: 0.24611, time: 53.79896\n",
      "\n",
      "2020-08-16T09:41:56.864685\n",
      "LR: 9.830400000000002e-06\n",
      "[RESULT]: Train. Epoch: 27, summary_loss: 0.37582, roc_auc: 0.95600, ap: 0.95038, time: 196.11104\n",
      "[RESULT]: Val. Epoch: 27, summary_loss: 0.27584, roc_auc: 0.87856, ap: 0.27062, time: 52.60911\n",
      "\n",
      "2020-08-16T09:46:05.586788\n",
      "LR: 9.830400000000002e-06\n",
      "[RESULT]: Train. Epoch: 28, summary_loss: 0.37608, roc_auc: 0.95595, ap: 0.94987, time: 194.81315\n",
      "[RESULT]: Val. Epoch: 28, summary_loss: 0.29091, roc_auc: 0.89823, ap: 0.26485, time: 52.46837\n",
      "\n",
      "2020-08-16T09:50:12.967297\n",
      "LR: 9.830400000000002e-06\n",
      "[RESULT]: Train. Epoch: 29, summary_loss: 0.36470, roc_auc: 0.96214, ap: 0.95957, time: 198.91935\n",
      "[RESULT]: Val. Epoch: 29, summary_loss: 0.29017, roc_auc: 0.89288, ap: 0.29009, time: 53.79968\n",
      "(6474,) (6474,)\n",
      "Fitter prepared. Device is cuda:0\n",
      "\n",
      "2020-08-16T09:54:25.962080\n",
      "LR: 0.0\n",
      "0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:123: UserWarning:\n",
      "\n",
      "Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "\n",
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 0, summary_loss: 0.70547, roc_auc: 0.46675, ap: 0.47662, time: 202.91997\n",
      "[RESULT]: Val. Epoch: 0, summary_loss: 0.68118, roc_auc: 0.52974, ap: 0.01992, time: 53.88257\n",
      "\n",
      "2020-08-16T09:58:43.010120\n",
      "LR: 0.0\n",
      "1 4.9999999999999996e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 1, summary_loss: 0.62390, roc_auc: 0.75776, ap: 0.75056, time: 204.61754\n",
      "[RESULT]: Val. Epoch: 1, summary_loss: 0.40933, roc_auc: 0.78988, ap: 0.08930, time: 54.17444\n",
      "\n",
      "2020-08-16T10:03:02.052236\n",
      "LR: 4.9999999999999996e-06\n",
      "2 9.999999999999999e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 2, summary_loss: 0.53081, roc_auc: 0.84768, ap: 0.83199, time: 206.78939\n",
      "[RESULT]: Val. Epoch: 2, summary_loss: 0.31828, roc_auc: 0.83834, ap: 0.10999, time: 53.86544\n",
      "\n",
      "2020-08-16T10:07:22.981900\n",
      "LR: 9.999999999999999e-06\n",
      "3 1.5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 3, summary_loss: 0.51080, roc_auc: 0.86445, ap: 0.85343, time: 206.61685\n",
      "[RESULT]: Val. Epoch: 3, summary_loss: 0.31662, roc_auc: 0.86269, ap: 0.13524, time: 55.08891\n",
      "\n",
      "2020-08-16T10:11:44.940778\n",
      "LR: 1.5e-05\n",
      "4 1.9999999999999998e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 4, summary_loss: 0.49967, roc_auc: 0.87462, ap: 0.86185, time: 208.78643\n",
      "[RESULT]: Val. Epoch: 4, summary_loss: 0.28043, roc_auc: 0.88061, ap: 0.14910, time: 53.53045\n",
      "\n",
      "2020-08-16T10:16:07.532152\n",
      "LR: 1.9999999999999998e-05\n",
      "5 2.5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 5, summary_loss: 0.48878, roc_auc: 0.88406, ap: 0.87545, time: 204.98116\n",
      "[RESULT]: Val. Epoch: 5, summary_loss: 0.31887, roc_auc: 0.87754, ap: 0.19171, time: 52.77486\n",
      "\n",
      "2020-08-16T10:20:25.381853\n",
      "LR: 2.5e-05\n",
      "6 3e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 6, summary_loss: 0.47868, roc_auc: 0.89209, ap: 0.88593, time: 207.37764\n",
      "[RESULT]: Val. Epoch: 6, summary_loss: 0.27614, roc_auc: 0.89563, ap: 0.22757, time: 54.94153\n",
      "\n",
      "2020-08-16T10:24:47.999711\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 7, summary_loss: 0.45779, roc_auc: 0.90768, ap: 0.90275, time: 208.23031\n",
      "[RESULT]: Val. Epoch: 7, summary_loss: 0.30934, roc_auc: 0.87979, ap: 0.19953, time: 54.05388\n",
      "\n",
      "2020-08-16T10:29:10.285998\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 8, summary_loss: 0.45637, roc_auc: 0.90887, ap: 0.90399, time: 211.87933\n",
      "[RESULT]: Val. Epoch: 8, summary_loss: 0.29879, roc_auc: 0.88510, ap: 0.25040, time: 55.61575\n",
      "\n",
      "2020-08-16T10:33:37.884855\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 9, summary_loss: 0.44504, roc_auc: 0.91674, ap: 0.90902, time: 208.20872\n",
      "[RESULT]: Val. Epoch: 9, summary_loss: 0.27417, roc_auc: 0.87688, ap: 0.22934, time: 54.12822\n",
      "\n",
      "2020-08-16T10:38:00.322942\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 10, summary_loss: 0.44362, roc_auc: 0.91730, ap: 0.91155, time: 205.78795\n",
      "[RESULT]: Val. Epoch: 10, summary_loss: 0.29260, roc_auc: 0.89405, ap: 0.27168, time: 54.55476\n",
      "\n",
      "2020-08-16T10:42:20.769797\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 11, summary_loss: 0.43034, roc_auc: 0.92607, ap: 0.92101, time: 207.57077\n",
      "[RESULT]: Val. Epoch: 11, summary_loss: 0.27600, roc_auc: 0.88299, ap: 0.22181, time: 52.92490\n",
      "\n",
      "2020-08-16T10:46:41.267671\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 12, summary_loss: 0.42237, roc_auc: 0.93114, ap: 0.92714, time: 202.65139\n",
      "[RESULT]: Val. Epoch: 12, summary_loss: 0.32049, roc_auc: 0.90553, ap: 0.27554, time: 52.10173\n",
      "\n",
      "2020-08-16T10:50:56.216905\n",
      "LR: 2.4e-05\n",
      "[RESULT]: Train. Epoch: 13, summary_loss: 0.41852, roc_auc: 0.93374, ap: 0.93025, time: 200.89121\n",
      "[RESULT]: Val. Epoch: 13, summary_loss: 0.31134, roc_auc: 0.89852, ap: 0.29871, time: 53.15949\n",
      "\n",
      "2020-08-16T10:55:10.371864\n",
      "LR: 2.4e-05\n",
      "[RESULT]: Train. Epoch: 14, summary_loss: 0.41287, roc_auc: 0.93672, ap: 0.93235, time: 199.06787\n",
      "[RESULT]: Val. Epoch: 14, summary_loss: 0.28806, roc_auc: 0.88673, ap: 0.31281, time: 51.73133\n",
      "\n",
      "2020-08-16T10:59:21.276927\n",
      "LR: 2.4e-05\n",
      "[RESULT]: Train. Epoch: 15, summary_loss: 0.40175, roc_auc: 0.94346, ap: 0.94097, time: 194.61333\n",
      "[RESULT]: Val. Epoch: 15, summary_loss: 0.28506, roc_auc: 0.89386, ap: 0.30807, time: 52.14643\n",
      "\n",
      "2020-08-16T11:03:28.038995\n",
      "LR: 1.9200000000000003e-05\n",
      "[RESULT]: Train. Epoch: 16, summary_loss: 0.40550, roc_auc: 0.94117, ap: 0.93617, time: 199.15538\n",
      "[RESULT]: Val. Epoch: 16, summary_loss: 0.29580, roc_auc: 0.90127, ap: 0.31028, time: 52.52698\n",
      "\n",
      "2020-08-16T11:07:39.723552\n",
      "LR: 1.9200000000000003e-05\n",
      "[RESULT]: Train. Epoch: 17, summary_loss: 0.39446, roc_auc: 0.94739, ap: 0.94240, time: 198.74102\n",
      "[RESULT]: Val. Epoch: 17, summary_loss: 0.28836, roc_auc: 0.90340, ap: 0.31175, time: 51.96462\n",
      "\n",
      "2020-08-16T11:11:50.430988\n",
      "LR: 1.9200000000000003e-05\n",
      "[RESULT]: Train. Epoch: 18, summary_loss: 0.39626, roc_auc: 0.94572, ap: 0.94058, time: 202.51984\n",
      "[RESULT]: Val. Epoch: 18, summary_loss: 0.27622, roc_auc: 0.89506, ap: 0.30123, time: 52.49026\n",
      "\n",
      "2020-08-16T11:16:05.443033\n",
      "LR: 1.5360000000000002e-05\n",
      "[RESULT]: Train. Epoch: 19, summary_loss: 0.39092, roc_auc: 0.94897, ap: 0.94547, time: 200.64264\n",
      "[RESULT]: Val. Epoch: 19, summary_loss: 0.28040, roc_auc: 0.89202, ap: 0.31700, time: 53.64573\n",
      "\n",
      "2020-08-16T11:20:19.826917\n",
      "LR: 1.5360000000000002e-05\n",
      "[RESULT]: Train. Epoch: 20, summary_loss: 0.39002, roc_auc: 0.94910, ap: 0.94504, time: 205.90370\n",
      "[RESULT]: Val. Epoch: 20, summary_loss: 0.27800, roc_auc: 0.90375, ap: 0.32099, time: 54.72231\n",
      "\n",
      "2020-08-16T11:24:40.553183\n",
      "LR: 1.5360000000000002e-05\n",
      "[RESULT]: Train. Epoch: 21, summary_loss: 0.38131, roc_auc: 0.95319, ap: 0.94710, time: 205.49012\n",
      "[RESULT]: Val. Epoch: 21, summary_loss: 0.28079, roc_auc: 0.89196, ap: 0.31868, time: 53.91506\n",
      "\n",
      "2020-08-16T11:28:59.960547\n",
      "LR: 1.2288000000000002e-05\n",
      "[RESULT]: Train. Epoch: 22, summary_loss: 0.38589, roc_auc: 0.95105, ap: 0.94651, time: 211.72987\n",
      "[RESULT]: Val. Epoch: 22, summary_loss: 0.27544, roc_auc: 0.90486, ap: 0.35998, time: 53.98753\n",
      "\n",
      "2020-08-16T11:33:25.782730\n",
      "LR: 1.2288000000000002e-05\n",
      "[RESULT]: Train. Epoch: 23, summary_loss: 0.38354, roc_auc: 0.95248, ap: 0.94754, time: 210.64344\n",
      "[RESULT]: Val. Epoch: 23, summary_loss: 0.27361, roc_auc: 0.90176, ap: 0.34403, time: 53.87370\n",
      "\n",
      "2020-08-16T11:37:50.396086\n",
      "LR: 1.2288000000000002e-05\n",
      "[RESULT]: Train. Epoch: 24, summary_loss: 0.38462, roc_auc: 0.95220, ap: 0.94792, time: 208.47932\n",
      "[RESULT]: Val. Epoch: 24, summary_loss: 0.28735, roc_auc: 0.90360, ap: 0.35346, time: 53.26928\n",
      "\n",
      "2020-08-16T11:42:12.147023\n",
      "LR: 1.2288000000000002e-05\n",
      "[RESULT]: Train. Epoch: 25, summary_loss: 0.37977, roc_auc: 0.95450, ap: 0.95121, time: 212.21725\n",
      "[RESULT]: Val. Epoch: 25, summary_loss: 0.28471, roc_auc: 0.90993, ap: 0.33890, time: 55.13944\n",
      "\n",
      "2020-08-16T11:46:39.609314\n",
      "LR: 1.2288000000000002e-05\n",
      "[RESULT]: Train. Epoch: 26, summary_loss: 0.37279, roc_auc: 0.95854, ap: 0.95650, time: 211.39211\n",
      "[RESULT]: Val. Epoch: 26, summary_loss: 0.26869, roc_auc: 0.89274, ap: 0.36495, time: 56.48713\n",
      "\n",
      "2020-08-16T11:51:07.691352\n",
      "LR: 1.2288000000000002e-05\n",
      "[RESULT]: Train. Epoch: 27, summary_loss: 0.37373, roc_auc: 0.95698, ap: 0.95284, time: 212.18962\n",
      "[RESULT]: Val. Epoch: 27, summary_loss: 0.27233, roc_auc: 0.90158, ap: 0.33343, time: 55.28125\n",
      "\n",
      "2020-08-16T11:55:35.164067\n",
      "LR: 1.2288000000000002e-05\n",
      "[RESULT]: Train. Epoch: 28, summary_loss: 0.36902, roc_auc: 0.96000, ap: 0.95568, time: 208.61447\n",
      "[RESULT]: Val. Epoch: 28, summary_loss: 0.28058, roc_auc: 0.90512, ap: 0.38360, time: 55.08346\n",
      "\n",
      "2020-08-16T11:59:58.953587\n",
      "LR: 1.2288000000000002e-05\n",
      "[RESULT]: Train. Epoch: 29, summary_loss: 0.37092, roc_auc: 0.95868, ap: 0.95473, time: 212.86012\n",
      "[RESULT]: Val. Epoch: 29, summary_loss: 0.27768, roc_auc: 0.88714, ap: 0.36583, time: 54.94973\n",
      "(6428,) (6428,)\n",
      "Fitter prepared. Device is cuda:0\n",
      "\n",
      "2020-08-16T12:04:26.965027\n",
      "LR: 0.0\n",
      "0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:123: UserWarning:\n",
      "\n",
      "Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "\n",
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 0, summary_loss: 0.70600, roc_auc: 0.46286, ap: 0.47702, time: 211.11295\n",
      "[RESULT]: Val. Epoch: 0, summary_loss: 0.68130, roc_auc: 0.52171, ap: 0.02003, time: 57.82707\n",
      "\n",
      "2020-08-16T12:08:56.150733\n",
      "LR: 0.0\n",
      "1 4.9999999999999996e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 1, summary_loss: 0.62681, roc_auc: 0.75450, ap: 0.74359, time: 210.32476\n",
      "[RESULT]: Val. Epoch: 1, summary_loss: 0.43128, roc_auc: 0.75272, ap: 0.06570, time: 56.66467\n",
      "\n",
      "2020-08-16T12:13:23.391467\n",
      "LR: 4.9999999999999996e-06\n",
      "2 9.999999999999999e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 2, summary_loss: 0.53324, roc_auc: 0.84652, ap: 0.83293, time: 209.45205\n",
      "[RESULT]: Val. Epoch: 2, summary_loss: 0.29341, roc_auc: 0.83324, ap: 0.09122, time: 55.22353\n",
      "\n",
      "2020-08-16T12:17:48.391040\n",
      "LR: 9.999999999999999e-06\n",
      "3 1.5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 3, summary_loss: 0.50982, roc_auc: 0.86569, ap: 0.85427, time: 206.79575\n",
      "[RESULT]: Val. Epoch: 3, summary_loss: 0.31487, roc_auc: 0.85441, ap: 0.11689, time: 57.18151\n",
      "\n",
      "2020-08-16T12:22:12.552313\n",
      "LR: 1.5e-05\n",
      "4 1.9999999999999998e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 4, summary_loss: 0.50459, roc_auc: 0.86921, ap: 0.86024, time: 212.07103\n",
      "[RESULT]: Val. Epoch: 4, summary_loss: 0.30997, roc_auc: 0.85522, ap: 0.12651, time: 58.31130\n",
      "\n",
      "2020-08-16T12:26:43.213685\n",
      "LR: 1.9999999999999998e-05\n",
      "5 2.5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 5, summary_loss: 0.49455, roc_auc: 0.87857, ap: 0.86616, time: 208.22151\n",
      "[RESULT]: Val. Epoch: 5, summary_loss: 0.30791, roc_auc: 0.85883, ap: 0.13376, time: 57.22123\n",
      "\n",
      "2020-08-16T12:31:08.841575\n",
      "LR: 2.5e-05\n",
      "6 3e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 6, summary_loss: 0.47516, roc_auc: 0.89531, ap: 0.88988, time: 213.15021\n",
      "[RESULT]: Val. Epoch: 6, summary_loss: 0.28439, roc_auc: 0.88055, ap: 0.16264, time: 57.31101\n",
      "\n",
      "2020-08-16T12:35:39.681404\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 7, summary_loss: 0.46645, roc_auc: 0.90163, ap: 0.89325, time: 207.75987\n",
      "[RESULT]: Val. Epoch: 7, summary_loss: 0.28865, roc_auc: 0.87806, ap: 0.17728, time: 55.29054\n",
      "\n",
      "2020-08-16T12:40:02.828062\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 8, summary_loss: 0.45305, roc_auc: 0.91076, ap: 0.90278, time: 207.65717\n",
      "[RESULT]: Val. Epoch: 8, summary_loss: 0.28424, roc_auc: 0.88281, ap: 0.20374, time: 56.71211\n",
      "\n",
      "2020-08-16T12:44:27.530416\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 9, summary_loss: 0.44256, roc_auc: 0.91825, ap: 0.91096, time: 214.36315\n",
      "[RESULT]: Val. Epoch: 9, summary_loss: 0.28428, roc_auc: 0.89670, ap: 0.21002, time: 59.17488\n",
      "\n",
      "2020-08-16T12:49:01.251735\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 10, summary_loss: 0.44068, roc_auc: 0.91947, ap: 0.91543, time: 209.20485\n",
      "[RESULT]: Val. Epoch: 10, summary_loss: 0.27853, roc_auc: 0.89236, ap: 0.22935, time: 56.44255\n",
      "\n",
      "2020-08-16T12:53:27.078116\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 11, summary_loss: 0.43101, roc_auc: 0.92579, ap: 0.92041, time: 212.71441\n",
      "[RESULT]: Val. Epoch: 11, summary_loss: 0.27352, roc_auc: 0.90444, ap: 0.23425, time: 57.07373\n",
      "\n",
      "2020-08-16T12:57:57.139279\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 12, summary_loss: 0.42445, roc_auc: 0.92950, ap: 0.92086, time: 211.14195\n",
      "[RESULT]: Val. Epoch: 12, summary_loss: 0.27569, roc_auc: 0.89114, ap: 0.22768, time: 60.01876\n",
      "\n",
      "2020-08-16T13:02:28.302376\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 13, summary_loss: 0.41823, roc_auc: 0.93393, ap: 0.93029, time: 213.58736\n",
      "[RESULT]: Val. Epoch: 13, summary_loss: 0.27824, roc_auc: 0.89370, ap: 0.22736, time: 60.02947\n",
      "\n",
      "2020-08-16T13:07:01.920907\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 14, summary_loss: 0.41283, roc_auc: 0.93650, ap: 0.92979, time: 210.57216\n",
      "[RESULT]: Val. Epoch: 14, summary_loss: 0.26892, roc_auc: 0.88126, ap: 0.22075, time: 59.80223\n",
      "\n",
      "2020-08-16T13:11:32.396607\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 15, summary_loss: 0.41115, roc_auc: 0.93773, ap: 0.93336, time: 215.57086\n",
      "[RESULT]: Val. Epoch: 15, summary_loss: 0.28165, roc_auc: 0.89902, ap: 0.20362, time: 60.60909\n",
      "\n",
      "2020-08-16T13:16:08.578955\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 16, summary_loss: 0.40625, roc_auc: 0.94035, ap: 0.93396, time: 212.27985\n",
      "[RESULT]: Val. Epoch: 16, summary_loss: 0.26020, roc_auc: 0.90180, ap: 0.26304, time: 58.69294\n",
      "\n",
      "2020-08-16T13:20:39.742459\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 17, summary_loss: 0.39804, roc_auc: 0.94491, ap: 0.93952, time: 211.88663\n",
      "[RESULT]: Val. Epoch: 17, summary_loss: 0.27458, roc_auc: 0.90992, ap: 0.24849, time: 61.21495\n",
      "\n",
      "2020-08-16T13:25:13.006931\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 18, summary_loss: 0.39415, roc_auc: 0.94718, ap: 0.94457, time: 215.05306\n",
      "[RESULT]: Val. Epoch: 18, summary_loss: 0.27781, roc_auc: 0.92128, ap: 0.27814, time: 57.97479\n",
      "\n",
      "2020-08-16T13:29:46.216170\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 19, summary_loss: 0.39379, roc_auc: 0.94699, ap: 0.94087, time: 209.58511\n",
      "[RESULT]: Val. Epoch: 19, summary_loss: 0.27685, roc_auc: 0.92159, ap: 0.27698, time: 56.96263\n",
      "\n",
      "2020-08-16T13:34:12.859780\n",
      "LR: 2.4e-05\n",
      "[RESULT]: Train. Epoch: 20, summary_loss: 0.38707, roc_auc: 0.95037, ap: 0.94468, time: 213.15906\n",
      "[RESULT]: Val. Epoch: 20, summary_loss: 0.26355, roc_auc: 0.90498, ap: 0.25626, time: 57.43559\n",
      "\n",
      "2020-08-16T13:38:43.456725\n",
      "LR: 2.4e-05\n",
      "[RESULT]: Train. Epoch: 21, summary_loss: 0.38767, roc_auc: 0.95043, ap: 0.94689, time: 207.93285\n",
      "[RESULT]: Val. Epoch: 21, summary_loss: 0.25365, roc_auc: 0.91506, ap: 0.29511, time: 56.64858\n",
      "\n",
      "2020-08-16T13:43:08.240080\n",
      "LR: 2.4e-05\n",
      "[RESULT]: Train. Epoch: 22, summary_loss: 0.37941, roc_auc: 0.95438, ap: 0.95133, time: 204.61677\n",
      "[RESULT]: Val. Epoch: 22, summary_loss: 0.27576, roc_auc: 0.91443, ap: 0.29872, time: 56.82936\n",
      "\n",
      "2020-08-16T13:47:29.779317\n",
      "LR: 2.4e-05\n",
      "[RESULT]: Train. Epoch: 23, summary_loss: 0.37307, roc_auc: 0.95773, ap: 0.95411, time: 210.37646\n",
      "[RESULT]: Val. Epoch: 23, summary_loss: 0.27091, roc_auc: 0.91249, ap: 0.28158, time: 55.93698\n",
      "\n",
      "2020-08-16T13:51:56.094663\n",
      "LR: 2.4e-05\n",
      "[RESULT]: Train. Epoch: 24, summary_loss: 0.36930, roc_auc: 0.95901, ap: 0.95441, time: 207.68206\n",
      "[RESULT]: Val. Epoch: 24, summary_loss: 0.27065, roc_auc: 0.93083, ap: 0.30661, time: 57.26631\n",
      "\n",
      "2020-08-16T13:56:21.244041\n",
      "LR: 1.9200000000000003e-05\n",
      "[RESULT]: Train. Epoch: 25, summary_loss: 0.36716, roc_auc: 0.96014, ap: 0.95589, time: 211.53836\n",
      "[RESULT]: Val. Epoch: 25, summary_loss: 0.25715, roc_auc: 0.90379, ap: 0.28139, time: 55.69043\n",
      "\n",
      "2020-08-16T14:00:48.475179\n",
      "LR: 1.9200000000000003e-05\n",
      "[RESULT]: Train. Epoch: 26, summary_loss: 0.36429, roc_auc: 0.96145, ap: 0.95775, time: 205.71404\n",
      "[RESULT]: Val. Epoch: 26, summary_loss: 0.26649, roc_auc: 0.93146, ap: 0.30714, time: 54.31403\n",
      "\n",
      "2020-08-16T14:05:08.682798\n",
      "LR: 1.9200000000000003e-05\n",
      "[RESULT]: Train. Epoch: 27, summary_loss: 0.36082, roc_auc: 0.96247, ap: 0.95736, time: 207.37017\n",
      "[RESULT]: Val. Epoch: 27, summary_loss: 0.29041, roc_auc: 0.91425, ap: 0.30068, time: 55.55957\n",
      "\n",
      "2020-08-16T14:09:31.614846\n",
      "LR: 1.5360000000000002e-05\n",
      "[RESULT]: Train. Epoch: 28, summary_loss: 0.35212, roc_auc: 0.96740, ap: 0.96542, time: 204.57472\n",
      "[RESULT]: Val. Epoch: 28, summary_loss: 0.27214, roc_auc: 0.90764, ap: 0.26625, time: 54.97365\n",
      "\n",
      "2020-08-16T14:13:51.165122\n",
      "LR: 1.5360000000000002e-05\n",
      "[RESULT]: Train. Epoch: 29, summary_loss: 0.35682, roc_auc: 0.96504, ap: 0.96167, time: 201.53023\n",
      "[RESULT]: Val. Epoch: 29, summary_loss: 0.29049, roc_auc: 0.91753, ap: 0.27724, time: 56.80126\n",
      "(6678,) (6678,)\n",
      "Fitter prepared. Device is cuda:0\n",
      "\n",
      "2020-08-16T14:18:09.753882\n",
      "LR: 0.0\n",
      "0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:123: UserWarning:\n",
      "\n",
      "Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "\n",
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 0, summary_loss: 0.70530, roc_auc: 0.46708, ap: 0.48020, time: 207.98158\n",
      "[RESULT]: Val. Epoch: 0, summary_loss: 0.69655, roc_auc: 0.48641, ap: 0.01777, time: 57.45046\n",
      "\n",
      "2020-08-16T14:22:35.496276\n",
      "LR: 0.0\n",
      "1 4.9999999999999996e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 1, summary_loss: 0.62760, roc_auc: 0.74815, ap: 0.73262, time: 206.87494\n",
      "[RESULT]: Val. Epoch: 1, summary_loss: 0.42700, roc_auc: 0.79800, ap: 0.07496, time: 56.35379\n",
      "\n",
      "2020-08-16T14:26:58.955587\n",
      "LR: 4.9999999999999996e-06\n",
      "2 9.999999999999999e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 2, summary_loss: 0.52765, roc_auc: 0.85064, ap: 0.83316, time: 207.02543\n",
      "[RESULT]: Val. Epoch: 2, summary_loss: 0.33266, roc_auc: 0.87360, ap: 0.12108, time: 54.81017\n",
      "\n",
      "2020-08-16T14:31:21.064361\n",
      "LR: 9.999999999999999e-06\n",
      "3 1.5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 3, summary_loss: 0.51282, roc_auc: 0.86259, ap: 0.85140, time: 200.55420\n",
      "[RESULT]: Val. Epoch: 3, summary_loss: 0.34934, roc_auc: 0.87321, ap: 0.16385, time: 52.78483\n",
      "\n",
      "2020-08-16T14:35:34.497622\n",
      "LR: 1.5e-05\n",
      "4 1.9999999999999998e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 4, summary_loss: 0.49837, roc_auc: 0.87534, ap: 0.86774, time: 200.17182\n",
      "[RESULT]: Val. Epoch: 4, summary_loss: 0.30782, roc_auc: 0.87676, ap: 0.18719, time: 53.26176\n",
      "\n",
      "2020-08-16T14:39:48.233702\n",
      "LR: 1.9999999999999998e-05\n",
      "5 2.5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 5, summary_loss: 0.48740, roc_auc: 0.88479, ap: 0.87391, time: 198.82556\n",
      "[RESULT]: Val. Epoch: 5, summary_loss: 0.28889, roc_auc: 0.88860, ap: 0.20115, time: 53.77740\n",
      "\n",
      "2020-08-16T14:44:01.113513\n",
      "LR: 2.5e-05\n",
      "6 3e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhzhu/anaconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning:\n",
      "\n",
      "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT]: Train. Epoch: 6, summary_loss: 0.47454, roc_auc: 0.89543, ap: 0.89019, time: 197.82608\n",
      "[RESULT]: Val. Epoch: 6, summary_loss: 0.30202, roc_auc: 0.89414, ap: 0.19624, time: 52.89322\n",
      "\n",
      "2020-08-16T14:48:11.980834\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 7, summary_loss: 0.46830, roc_auc: 0.90011, ap: 0.89554, time: 200.17530\n",
      "[RESULT]: Val. Epoch: 7, summary_loss: 0.29990, roc_auc: 0.90314, ap: 0.20910, time: 54.08786\n",
      "\n",
      "2020-08-16T14:52:26.422792\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 8, summary_loss: 0.46280, roc_auc: 0.90382, ap: 0.89668, time: 197.20820\n",
      "[RESULT]: Val. Epoch: 8, summary_loss: 0.29615, roc_auc: 0.89605, ap: 0.20631, time: 53.80418\n",
      "\n",
      "2020-08-16T14:56:37.437794\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 9, summary_loss: 0.44283, roc_auc: 0.91816, ap: 0.91527, time: 197.46144\n",
      "[RESULT]: Val. Epoch: 9, summary_loss: 0.29906, roc_auc: 0.90675, ap: 0.25082, time: 53.91895\n",
      "\n",
      "2020-08-16T15:00:49.021007\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 10, summary_loss: 0.43755, roc_auc: 0.92166, ap: 0.91940, time: 200.40399\n",
      "[RESULT]: Val. Epoch: 10, summary_loss: 0.29063, roc_auc: 0.90769, ap: 0.23587, time: 54.75790\n",
      "\n",
      "2020-08-16T15:05:04.286165\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 11, summary_loss: 0.42947, roc_auc: 0.92671, ap: 0.92100, time: 199.09489\n",
      "[RESULT]: Val. Epoch: 11, summary_loss: 0.27188, roc_auc: 0.91069, ap: 0.28333, time: 53.08421\n",
      "\n",
      "2020-08-16T15:09:16.728207\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 12, summary_loss: 0.42053, roc_auc: 0.93237, ap: 0.92871, time: 196.97361\n",
      "[RESULT]: Val. Epoch: 12, summary_loss: 0.30612, roc_auc: 0.91802, ap: 0.22917, time: 54.02217\n",
      "\n",
      "2020-08-16T15:13:27.815600\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 13, summary_loss: 0.41918, roc_auc: 0.93247, ap: 0.92712, time: 199.40040\n",
      "[RESULT]: Val. Epoch: 13, summary_loss: 0.29725, roc_auc: 0.93216, ap: 0.23864, time: 53.84263\n",
      "\n",
      "2020-08-16T15:17:41.160401\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 14, summary_loss: 0.40949, roc_auc: 0.93876, ap: 0.93501, time: 199.35450\n",
      "[RESULT]: Val. Epoch: 14, summary_loss: 0.28886, roc_auc: 0.92312, ap: 0.27671, time: 54.66780\n",
      "\n",
      "2020-08-16T15:21:55.184893\n",
      "LR: 2.4e-05\n",
      "[RESULT]: Train. Epoch: 15, summary_loss: 0.40698, roc_auc: 0.93981, ap: 0.93617, time: 201.38914\n",
      "[RESULT]: Val. Epoch: 15, summary_loss: 0.27930, roc_auc: 0.92585, ap: 0.31240, time: 55.51436\n",
      "\n",
      "2020-08-16T15:26:12.182056\n",
      "LR: 2.4e-05\n",
      "[RESULT]: Train. Epoch: 16, summary_loss: 0.40498, roc_auc: 0.94095, ap: 0.93667, time: 210.11848\n",
      "[RESULT]: Val. Epoch: 16, summary_loss: 0.28232, roc_auc: 0.91505, ap: 0.28335, time: 55.15364\n",
      "\n",
      "2020-08-16T15:30:37.456471\n",
      "LR: 2.4e-05\n",
      "[RESULT]: Train. Epoch: 17, summary_loss: 0.40089, roc_auc: 0.94329, ap: 0.94009, time: 206.46445\n",
      "[RESULT]: Val. Epoch: 17, summary_loss: 0.27901, roc_auc: 0.91856, ap: 0.31758, time: 55.24238\n",
      "\n",
      "2020-08-16T15:34:59.257004\n",
      "LR: 1.9200000000000003e-05\n",
      "[RESULT]: Train. Epoch: 18, summary_loss: 0.39593, roc_auc: 0.94629, ap: 0.94294, time: 210.91896\n",
      "[RESULT]: Val. Epoch: 18, summary_loss: 0.27050, roc_auc: 0.91456, ap: 0.28991, time: 57.62705\n",
      "\n",
      "2020-08-16T15:39:27.896019\n",
      "LR: 1.9200000000000003e-05\n",
      "[RESULT]: Train. Epoch: 19, summary_loss: 0.39101, roc_auc: 0.94892, ap: 0.94410, time: 208.28757\n",
      "[RESULT]: Val. Epoch: 19, summary_loss: 0.27426, roc_auc: 0.93180, ap: 0.33279, time: 56.07860\n",
      "\n",
      "2020-08-16T15:43:52.359781\n",
      "LR: 1.9200000000000003e-05\n",
      "[RESULT]: Train. Epoch: 20, summary_loss: 0.38739, roc_auc: 0.95038, ap: 0.94560, time: 210.73600\n",
      "[RESULT]: Val. Epoch: 20, summary_loss: 0.26956, roc_auc: 0.91477, ap: 0.28482, time: 55.52763\n",
      "\n",
      "2020-08-16T15:48:18.721986\n",
      "LR: 1.9200000000000003e-05\n",
      "[RESULT]: Train. Epoch: 21, summary_loss: 0.38473, roc_auc: 0.95198, ap: 0.94722, time: 206.67334\n",
      "[RESULT]: Val. Epoch: 21, summary_loss: 0.29541, roc_auc: 0.92083, ap: 0.31200, time: 55.53762\n",
      "\n",
      "2020-08-16T15:52:40.935201\n",
      "LR: 1.9200000000000003e-05\n",
      "[RESULT]: Train. Epoch: 22, summary_loss: 0.38120, roc_auc: 0.95381, ap: 0.95005, time: 211.27351\n",
      "[RESULT]: Val. Epoch: 22, summary_loss: 0.27964, roc_auc: 0.92815, ap: 0.29317, time: 56.88647\n",
      "\n",
      "2020-08-16T15:57:09.097192\n",
      "LR: 1.9200000000000003e-05\n",
      "[RESULT]: Train. Epoch: 23, summary_loss: 0.38205, roc_auc: 0.95333, ap: 0.94892, time: 209.12087\n",
      "[RESULT]: Val. Epoch: 23, summary_loss: 0.28931, roc_auc: 0.92331, ap: 0.31823, time: 55.53264\n",
      "\n",
      "2020-08-16T16:01:33.752768\n",
      "LR: 1.5360000000000002e-05\n",
      "[RESULT]: Train. Epoch: 24, summary_loss: 0.37627, roc_auc: 0.95588, ap: 0.95191, time: 212.17965\n",
      "[RESULT]: Val. Epoch: 24, summary_loss: 0.27167, roc_auc: 0.92477, ap: 0.33176, time: 55.82131\n",
      "\n",
      "2020-08-16T16:06:01.755595\n",
      "LR: 1.5360000000000002e-05\n",
      "[RESULT]: Train. Epoch: 25, summary_loss: 0.37766, roc_auc: 0.95518, ap: 0.95150, time: 208.66087\n",
      "[RESULT]: Val. Epoch: 25, summary_loss: 0.26393, roc_auc: 0.92182, ap: 0.34131, time: 56.89584\n",
      "\n",
      "2020-08-16T16:10:27.564505\n",
      "LR: 1.5360000000000002e-05\n",
      "[RESULT]: Train. Epoch: 26, summary_loss: 0.36926, roc_auc: 0.95951, ap: 0.95609, time: 213.60748\n",
      "[RESULT]: Val. Epoch: 26, summary_loss: 0.26447, roc_auc: 0.91600, ap: 0.32279, time: 56.82007\n",
      "\n",
      "2020-08-16T16:14:57.994234\n",
      "LR: 1.5360000000000002e-05\n",
      "[RESULT]: Train. Epoch: 27, summary_loss: 0.36604, roc_auc: 0.96077, ap: 0.95706, time: 210.54238\n",
      "[RESULT]: Val. Epoch: 27, summary_loss: 0.27984, roc_auc: 0.91406, ap: 0.28302, time: 56.52350\n",
      "\n",
      "2020-08-16T16:19:25.062034\n",
      "LR: 1.5360000000000002e-05\n",
      "[RESULT]: Train. Epoch: 28, summary_loss: 0.36572, roc_auc: 0.96106, ap: 0.95911, time: 214.50812\n",
      "[RESULT]: Val. Epoch: 28, summary_loss: 0.28425, roc_auc: 0.91476, ap: 0.31163, time: 57.15736\n",
      "\n",
      "2020-08-16T16:23:56.729598\n",
      "LR: 1.2288000000000002e-05\n",
      "[RESULT]: Train. Epoch: 29, summary_loss: 0.36395, roc_auc: 0.96138, ap: 0.95774, time: 208.16556\n",
      "[RESULT]: Val. Epoch: 29, summary_loss: 0.28641, roc_auc: 0.92285, ap: 0.27409, time: 55.66698\n",
      "(6633,) (6633,)\n",
      "all_roc_auc is: 0.9182309520146698\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "all_true = [np.array([]), np.array([]), np.array([]), np.array([]), np.array([])]\n",
    "all_pred = [np.array([]), np.array([]), np.array([]), np.array([]), np.array([])]\n",
    "\n",
    "for fold_number in range(5):      # range(5)\n",
    "    all_true[fold_number], all_pred[fold_number] = train_fold(fold_number=fold_number)\n",
    "    print(all_true[fold_number].shape, all_pred[fold_number].shape)\n",
    "\n",
    "final_true = np.hstack((all_true[0], all_true[1], all_true[2], all_true[3], all_true[4]))\n",
    "final_pred = np.hstack((all_pred[0], all_pred[1], all_pred[2], all_pred[3], all_pred[4]))\n",
    "K = pd.DataFrame(columns = [\"true\", \"pred\"])\n",
    "K['true'] = final_true\n",
    "K['pred'] = final_pred\n",
    "K.to_csv('model/meta_b3_new/512_16/oof.csv',index=False)\n",
    "al_auc = sklearn.metrics.roc_auc_score(final_true, final_pred)\n",
    "print(\"all_roc_auc is:\", al_auc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
